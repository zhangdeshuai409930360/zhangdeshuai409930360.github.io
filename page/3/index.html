<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="baidu-site-verification" content="L6Lm9d5Crl"/>
  
  
  
  
  <title>Handsome</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Handsome">
<meta property="og:url" content="https://zhangdeshuai409930360.github.io/page/3/index.html">
<meta property="og:site_name" content="Handsome">
<meta property="og:locale" content="zh_CN">
<meta name="twitter:card" content="summary">
  
    <link rel="alternative" href="/atom.xml" title="Handsome" type="application/atom+xml">
  
  
    <link rel="icon" href="/img/favicon.png">
  
  
  
<link rel="stylesheet" href="//cdn.bootcss.com/animate.css/3.5.0/animate.min.css">

  
  
<link rel="stylesheet" href="/css/style.css">

  <link rel="stylesheet" href="/font-awesome/css/font-awesome.min.css">
  <link rel="apple-touch-icon" href="/apple-touch-icon.png">
  
    
    
  
  
      <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  
  <!-- 加载特效 -->
    <script src="/js/pace.js"></script>
    <link href="/css/pace/pace-theme-flash.css" rel="stylesheet" />
  <script>
      var yiliaConfig = {
          fancybox: true,
          animate: true,
          isHome: true,
          isPost: false,
          isArchive: false,
          isTag: false,
          isCategory: false,
          open_in_new: false
      }
  </script>
<meta name="generator" content="Hexo 4.2.0"></head>
<body>
  <div id="container">
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
    <header id="header" class="inner">
        
<script src="https://7.url.cn/edu/jslib/comb/require-2.1.6,jquery-1.9.1.min.js"></script>

        <a href="/" class="profilepic">
            
            <img lazy-src="/img/avatar.png" class="js-avatar">
            
        </a>
        <hgroup>
          <h1 class="header-author"><a href="/">Handsome</a></h1>
        </hgroup>
        
        
            <form>
                <input type="text" class="st-default-search-input search" id="local-search-input" placeholder="搜索一下" autocomplete="off">
            </form>
            <div id="local-search-result"></div>
        
        
            <script type="text/javascript">
                (function() {
                    'use strict';
                    function getMatchData(keyword, data) {
                        var matchData = [];
                        for(var i =0;i<data.length;i++){
                            if(data[i].title.toLowerCase().indexOf(keyword)>=0) 
                                matchData.push(data[i])
                        }
                        return matchData;
                    }
                    var $input = $('#local-search-input');
                    var $resultContent = $('#local-search-result');
                    $input.keyup(function(){
                        $.ajax({
                            url: '/search.json',
                            dataType: "json",
                            success: function( json ) {
                                var str='<ul class=\"search-result-list\">';                
                                var keyword = $input.val().trim().toLowerCase();
                                $resultContent.innerHTML = "";
                                if ($input.val().trim().length <= 0) {
                                    $resultContent.empty();
                                    $('#switch-area').show();
                                    return;
                                }
                                var results = getMatchData(keyword, json);
                                if(results.length === 0){
                                    $resultContent.empty();
                                    $('#switch-area').show();
                                    return;
                                } 
                                for(var i =0; i<results.length; i++){
                                    str += "<li><a href='"+ results[i].url +"' class='search-result-title'>"+ results[i].title +"</a></li>";
                                }
                                str += "</ul>";
                                $resultContent.empty();
                                $resultContent.append(str);
                                $('#switch-area').hide();
                            }
                        });
                    });
                })();
            </script>
        
        
            <div id="switch-btn" class="switch-btn">
                <div class="icon">
                    <div class="icon-ctn">
                        <div class="icon-wrap icon-house" data-idx="0">
                            <div class="birdhouse"></div>
                            <div class="birdhouse_holes"></div>
                        </div>
                        <div class="icon-wrap icon-ribbon hide" data-idx="1">
                            <div class="ribbon"></div>
                        </div>
                        
                        <div class="icon-wrap icon-link hide" data-idx="2">
                            <div class="loopback_l"></div>
                            <div class="loopback_r"></div>
                        </div>
                        
                        
                        <div class="icon-wrap icon-me hide" data-idx="3">
                            <div class="user"></div>
                            <div class="shoulder"></div>
                        </div>
                        
                    </div>
                </div>
                <div class="tips-box hide">
                    <div class="tips-arrow"></div>
                    <ul class="tips-inner">
                        <li>菜单</li>
                        <li>标签</li>
                        <li>友情链接</li>
                        
                        <li>关于我</li>
                        
                    </ul>
                </div>
            </div>
        
        <div id="switch-area" class="switch-area">
            <div class="switch-wrap">
                <section class="switch-part switch-part1">
                    <nav class="header-menu">
                        <ul>
                        
                            <li><a  href="/archives/">所有文章</a></li>
                        
                            <li><a  href="/categories/bigdata/">大数据</a></li>
                        
                            <li><a  href="/categories/java/">JAVA学习</a></li>
                        
                            <li><a  href="/categories/algorithm">算法学习</a></li>
                        
                            <li><a  href="/about/">关于我</a></li>
                        
                        </ul>
                    </nav>
                    <nav class="header-nav">
                        <ul class="social">
                            
                                <a class="fl github"  target="_blank" href="https://github.com/zhangdeshuai409930360" title="github">github</a>
                            
                                <a class="fl weibo"  target="_blank" href="https://weibo.com/u/3077230927/home?wvr=5" title="weibo">weibo</a>
                            
                                <a class="fl rss"  target="_blank" href="/" title="rss">rss</a>
                            
                        </ul>
                    </nav>
                </section>
                
                <section class="switch-part switch-part2">
                    <div class="widget tagcloud" id="js-tagcloud">
                        <a href="/tags/Atlas/" style="font-size: 10px;">Atlas</a> <a href="/tags/Datax/" style="font-size: 10px;">Datax</a> <a href="/tags/Druid/" style="font-size: 10px;">Druid</a> <a href="/tags/ELK/" style="font-size: 10px;">ELK</a> <a href="/tags/Flink/" style="font-size: 17.5px;">Flink</a> <a href="/tags/Flink-Spark/" style="font-size: 10px;">Flink,Spark</a> <a href="/tags/HIVE/" style="font-size: 10px;">HIVE</a> <a href="/tags/Hbase/" style="font-size: 10px;">Hbase</a> <a href="/tags/Hudi/" style="font-size: 10px;">Hudi</a> <a href="/tags/Oozie/" style="font-size: 12.5px;">Oozie</a> <a href="/tags/SQL/" style="font-size: 10px;">SQL</a> <a href="/tags/hadoop/" style="font-size: 12.5px;">hadoop</a> <a href="/tags/hive/" style="font-size: 10px;">hive</a> <a href="/tags/kafka/" style="font-size: 15px;">kafka</a> <a href="/tags/kerberos/" style="font-size: 10px;">kerberos</a> <a href="/tags/kylin-olap/" style="font-size: 10px;">kylin olap</a> <a href="/tags/python/" style="font-size: 12.5px;">python</a> <a href="/tags/shell/" style="font-size: 10px;">shell</a> <a href="/tags/spark/" style="font-size: 20px;">spark</a> <a href="/tags/spark-Structured/" style="font-size: 10px;">spark Structured</a> <a href="/tags/%E6%9E%B6%E6%9E%84/" style="font-size: 10px;">架构</a>
                    </div>
                </section>
                
                
                <section class="switch-part switch-part3">
                    <div id="js-friends">
                    <a target="_blank"  class="main-nav-link switch-friends-link" href="https://my.oschina.net/u/559635">oschina</a>
                    </div>
                </section>
                
                
                
                <section class="switch-part switch-part4">
                
                    <div id="js-aboutme">
                      关于博主
简介
90后，大数据开发工程师/JAVA工程师。
知人不必言尽，留三分余地与人，留些口德与己。
责人不必苛尽，留三分余地与人，留些肚量与己。
才能不必傲尽，留三分余地与人，留些内涵与己。
锋芒不必露尽，留三分余地与人，留些深敛与己。
有功不必邀尽，留三分余地与人，留些谦让与己。
2013.10-2016.03 深圳市时讯互联科技有限公司 JAVA/大数据开发工程师
2016.03-2017.08       深圳市华阳信通发展有限公司/大数据开发工程师
2017.08-2018.03       深圳市彩讯科技股份有限公司/大数据开发工程师
2018.03-至今       深圳市加推科技有限公司/大数据开发工程师     
 </div>
                </section>
                
            </div>
        </div>
    </header>
</div>

    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
      <div class="overlay">
          <div class="slider-trigger"></div>
          <h1 class="header-author js-mobile-header hide"><a href="/" title="回到主页">Handsome</a></h1>
      </div>
    <div class="intrude-less">
        <header id="header" class="inner">
            <a href="/" class="profilepic">
                
                    <img lazy-src="/img/avatar.png" class="js-avatar">
                
            </a>
            <hgroup>
              <h1 class="header-author"><a href="/" title="回到主页">Handsome</a></h1>
            </hgroup>
            
            <nav class="header-menu">
                <ul>
                
                    <li><a href="/archives/">所有文章</a></li>
                
                    <li><a href="/categories/bigdata/">大数据</a></li>
                
                    <li><a href="/categories/java/">JAVA学习</a></li>
                
                    <li><a href="/categories/algorithm">算法学习</a></li>
                
                    <li><a href="/about/">关于我</a></li>
                
                <div class="clearfix"></div>
                </ul>
            </nav>
            <nav class="header-nav">
                <div class="social">
                    
                        <a class="github" target="_blank" href="https://github.com/zhangdeshuai409930360" title="github">github</a>
                    
                        <a class="weibo" target="_blank" href="https://weibo.com/u/3077230927/home?wvr=5" title="weibo">weibo</a>
                    
                        <a class="rss" target="_blank" href="/" title="rss">rss</a>
                    
                </div>
            </nav>
        </header>
    </div>
</nav>

     <div class="body-wrap">
  
    <article id="post-28" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a  href="/2019/08/14/28/" class="article-date">
      <time datetime="2019-08-14T13:01:24.000Z" itemprop="datePublished">2019-08-14</time>
</a>

    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a  class="article-title" href="/2019/08/14/28/">Spark Yarn 的提交二种方式</a>
    </h1>
  


      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <h3 id="一、前述"><a href="#一、前述" class="headerlink" title="一、前述"></a>一、前述</h3><p> Spark可以和Yarn整合，将Application提交到Yarn上运行，和StandAlone提交模式一样，Yarn也有两种提交任务的方式。</p>
<h3 id="具体"><a href="#具体" class="headerlink" title="具体"></a>具体</h3><p>1、yarn-client提交任务方式</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">./spark-submit --master yarn  --class org.apache.spark.examples.SparkPi  ../lib/spark-examples-1.6.0-hadoop2.6.0.jar 100</span><br><span class="line">./spark-submit   --master yarn-lient   --class org.apache.spark.examples.SparkPi ../lib/spark-examples-1.6.0-hadoop2.6.0.jar 100</span><br><span class="line">./spark-submit  --master yarn --deploy-mode  client --class org.apache.spark.examples.SparkPi ../lib/spark-examples-1.6.0-hadoop2.6.0.jar 100</span><br></pre></td></tr></table></figure>


<p><img src="/images/44.png" alt="alt"></p>
<p>执行原理图解</p>
<p><img src="/images/45.png" alt="alt"></p>
<p>执行流程<br>1.客户端提交一个Application，在客户端启动一个Driver进程。<br>2.Driver进程会向RS(ResourceManager)发送请求，启动AM(ApplicationMaster)的资源。<br>3.RS收到请求，随机选择一台NM(NodeManager)启动AM。这里的NM相当于Standalone中的Worker节点。<br>4.AM启动后，会向RS请求一批container资源，用于启动Executor.<br>5.RS会找到一批NM返回给AM,用于启动Executor。<br>6.AM会向NM发送命令启动Executor。<br>7.Executor启动后，会反向注册给Driver，Driver发送task到Executor,执行情况和结果返回给Driver端。</p>
<p>总结<br>        1、Yarn-client模式同样是适用于测试，因为Driver运行在本地，Driver会与yarn集群中的Executor进行大量的通信，会造成客户机网卡流量的大量增加.</p>
<pre><code>2、 ApplicationMaster的作用：

         为当前的Application申请资源

         给NodeManager发送消息启动Executor。</code></pre><p>注意：ApplicationMaster有launchExecutor和申请资源的功能，并没有作业调度的功能。</p>
<p>2、yarn-cluster提交任务方式</p>
<p>提交命令</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">./spark-submit --master yarn --deploy-mode cluster  --class org.apache.spark.examples.SparkPi ../lib/spark-examples-1.6.0-hadoop2.6.0.jar 100</span><br><span class="line">./spark-submit   --master yarn-cluster  --class org.apache.spark.examples.SparkPi ../lib/spark-examples-1.6.0-hadoop2.6.0.jar 100</span><br></pre></td></tr></table></figure>
<p>结果在yarn的日志里面：</p>
<p><img src="/images/46.png" alt="alt"></p>
<p>执行原理<br><img src="/images/47.png" alt="alt"><br>执行流程<br>1.客户机提交Application应用程序，发送请求到RS(ResourceManager),请求启动AM(ApplicationMaster)。<br>2.RS收到请求后随机在一台NM(NodeManager)上启动AM（相当于Driver端）。<br>3.AM启动，AM发送请求到RS，请求一批container用于启动Executor。<br>4.RS返回一批NM节点给AM。<br>5.AM连接到NM,发送请求到NM启动Executor。<br>6.Executor反向注册到AM所在的节点的Driver。Driver发送task到Executor。</p>
<p>总结<br>        1、Yarn-Cluster主要用于生产环境中，因为Driver运行在Yarn集群中某一台nodeManager中，每次提交任务的Driver所在的机器都是随机的，不会产生某一台机器网卡流量激增的现象，缺点是任务提交后不能看到日志。只能通过yarn查看日志。</p>
<pre><code>2.ApplicationMaster的作用：

       为当前的Application申请资源

       给nodemanager发送消息 启动Excutor。

       任务调度。(这里和client模式的区别是AM具有调度能力，因为其就是Driver端，包含Driver进程)</code></pre>
      
    </div>
    
    <div class="article-info article-info-index">
      
      
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/bigdata/">bigdata</a>
    </div>


      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/spark/" rel="tag">spark</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>











  
    <article id="post-10" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a  href="/2019/07/14/10/" class="article-date">
      <time datetime="2019-07-14T03:01:24.000Z" itemprop="datePublished">2019-07-14</time>
</a>

    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a  class="article-title" href="/2019/07/14/10/">ELK日志采集logstash output -&gt; elasticsearch 数据写入性能优化。</a>
    </h1>
  


      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <h3 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h3><p>前些时间测试线上ELK环境，发现beats组件直连elasticsearch数据灌入异常快，但是过了logstash数据明显迟缓。判定logstah的灌入存在瓶颈。以下为logstash调优细节。</p>
<h3 id="环境"><a href="#环境" class="headerlink" title="环境"></a>环境</h3><p>本次针对的优化对象是线上的日志分析平台，主要数据源为基础服务器数据和应用日志<br>ES节点：顶配3点集群，各方面负载不高，无写入瓶颈<br>logstah节点：2个汇聚端，<br>网络：内网万兆传输，无瓶颈<br>数据量（条）：1~1.5w/s</p>
<h3 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h3><p><img src="/images/1.png" alt="alt"></p>
<h3 id="分析"><a href="#分析" class="headerlink" title="分析"></a>分析</h3><p>logstah的功能是一个管道，通过input灌入数据，filter过滤数据，output输入数据</p>
<p>input：filebeat和metricbeat总连接数为500左右，且观察日志无retry 或 timeout等输出，无明显瓶颈<br>filter和output：logstash的正则解析过程非常消耗资源，但是我们的节点资源消耗居然不高。在新版的logstash中优化了input，filter，output的线程模式，在配置文件中可以通过配置pipeline.workers来调整filter和output的线程数</p>
<h3 id="优化"><a href="#优化" class="headerlink" title="优化"></a>优化</h3><p>查询官网手册后，最影响logstash传输效率的参数有以下几个:<br>1、pipeline.workers：决定filter和output的线程数，官方建议大于CPU数，如果logstah节点是混用服务器，建议等于或小于CPU数<br>2、pipeline.batch.size：单个线程每次调用ES bulk index API时的事件数。这些时间将被放到内存中。最好的设定值是不断地测试，测试，测试。<br>3、pipeline.batch.size：单个线程每次调用ES bulk index API时的事件数。这些时间将被放到内存中。最好的设定值是不断地测试，测试，测试。<br>优化后的logstash<br>pipeline.batch.size: 2500<br>pipeline.batch.delay: 5<br>pipeline.workers: 8<br>pipeline.batch.size: 2500<br>pipeline.batch.delay: 50</p>
<h3 id="优化结果"><a href="#优化结果" class="headerlink" title="优化结果"></a>优化结果</h3><p><img src="/images/2.png" alt="alt"></p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/bigdata/">bigdata</a>
    </div>


      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/ELK/" rel="tag">ELK</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>











  
    <article id="post-13" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a  href="/2019/06/23/13/" class="article-date">
      <time datetime="2019-06-23T01:12:55.000Z" itemprop="datePublished">2019-06-23</time>
</a>

    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a  class="article-title" href="/2019/06/23/13/">SparkStructured StreamExecution：持续查询的运转引擎</a>
    </h1>
  


      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <h3 id="StreamExecution-的初始状态"><a href="#StreamExecution-的初始状态" class="headerlink" title="StreamExecution 的初始状态"></a>StreamExecution 的初始状态</h3><p>定义好 Dataset/DataFrame 的产生、变换和写出，再启动 StreamExection 去持续查询。这些 Dataset/DataFrame 的产生、变换和写出的信息就对应保存在 StreamExecution 非常重要的 3 个成员变量中：<br>1、sources: streaming data 的产生端（比如 kafka 等）<br>2、logicalPlan: DataFrame/Dataset 的一系列变换（即计算逻辑）<br>3、sink: 最终结果写出的接收端（比如 file system 等）</p>
<p>StreamExection 另外的重要成员变量是：<br>1、currentBatchId: 当前执行的 id<br>2、batchCommitLog: 已经成功处理过的批次有哪些<br>3、offsetLog, availableOffsets, committedOffsets: 当前执行需要处理的 source data 的 meta 信息<br>4、offsetSeqMetadata: 当前执行的 watermark 信息（event time 相关，本文暂不涉及、另文解析）等</p>
<p><img src="/images/6.png" alt="alt"></p>
<h3 id="StreamExecution-的持续查询"><a href="#StreamExecution-的持续查询" class="headerlink" title="StreamExecution 的持续查询"></a>StreamExecution 的持续查询</h3><p><img src="/images/7.png" alt="alt"><br>一次执行的过程如上图；这里有 6 个关键步骤:<br>1.StreamExecution 通过 Source.getOffset() 获取最新的 offsets，即最新的数据进度；<br>2.StreamExecution 将 offsets 等写入到 offsetLog 里<br>  这里的 offsetLog 是一个持久化的 WAL (Write-Ahead-Log)，是将来可用作故障恢复用<br>3.StreamExecution 构造本次执行的 LogicalPlan<br>  (3a) 将预先定义好的逻辑（即 StreamExecution 里的 logicalPlan 成员变量）制作一个副本出来<br>  (3b) 给定刚刚取到的 offsets，通过 Source.getBatch(offsets) 获取本执行新收到的数据的 Dataset/DataFrame 表示，并替换到 (3a) 中的副本里<br>  经过 (3a), (3b) 两步，构造完成的 LogicalPlan 就是针对本执行新收到的数据的 Dataset/DataFrame 变换（即整个处理逻辑）了<br>4.触发对本次执行的 LogicalPlan 的优化，得到 IncrementalExecution<br>  逻辑计划的优化：通过 Catalyst 优化器完成<br>  物理计划的生成与选择：结果是可以直接用于执行的 RDD DAG<br>  逻辑计划、优化的逻辑计划、物理计划、及最后结果 RDD DAG，合并起来就是 IncrementalExecution<br>5.将表示计算结果的 Dataset/DataFrame (包含 IncrementalExecution) 交给 Sink，即调用 Sink.add(ds/df)<br>6.计算完成后的 commit<br>  (6a) 通过 Source.commit() 告知 Source 数据已经完整处理结束；Source 可按需完成数据的 garbage-collection<br>  (6b) 将本次执行的批次 id 写入到 batchCommitLog 里</p>
<h3 id="StreamExecution-的持续查询（增量）"><a href="#StreamExecution-的持续查询（增量）" class="headerlink" title="StreamExecution 的持续查询（增量）"></a>StreamExecution 的持续查询（增量）</h3><p><img src="/images/8.png" alt="alt"><br>Structured Streaming 在编程模型上暴露给用户的是，每次持续查询看做面对全量数据（而不仅仅是本次执行信收到的数据），所以每次执行的结果是针对全量数据进行计算的结果。</p>
<p>但是在实际执行过程中，由于全量数据会越攒越多，那么每次对全量数据进行计算的代价和消耗会越来越大。</p>
<p>Structured Streaming 的做法是：<br>1.引入全局范围、高可用的 StateStore<br>2.转全量为增量，即在每次执行时：<br>  先从 StateStore 里 restore 出上次执行后的状态<br>  然后加入本执行的新数据，再进行计算<br>  如果有状态改变，将把改变的状态重新 save 到 StateStore 里<br>3.为了在 Dataset/DataFrame 框架里完成对 StateStore 的 restore 和 s如果在某个执行过程中发生 driver 故障，那么重新起来的 StreamExecution：<br>所以 Structured Streaming 在编程模型上暴露给用户的是，每次持续查询看做面对全量数据，但在具体实现上转换为增量的持续查询。</p>
<h3 id="故障恢复"><a href="#故障恢复" class="headerlink" title="故障恢复"></a>故障恢复</h3><p><img src="/images/9.png" alt="alt"><br>由于 exectutor 节点的故障可由 Spark 框架本身很好的 handle，不引起可用性问题，我们本节的故障恢复只讨论 driver 故障恢复。<br>1.如果在某个执行过程中发生 driver 故障，那么重新起来的 StreamExecution：<br>2.读取 WAL offsetlog 恢复出最新的 offsets 等；相当于取代正常流程里的 (1)(2) 步<br>3.读取 batchCommitLog 决定是否需要重做最近一个批次<br>4.如果需要，那么重做 (3a), (3b), (4), (5), (6a), (6b) 步<br>   这里第 (5) 步需要分两种情况讨论<br>   (i) 如果上次执行在 (5) 结束前即失效，那么本次执行里 sink 应该完整写出计算结果<br>   (ii) 如果上次执行在 (5) 结束后才失效，那么本次执行里 sink 可以重新写出计算结果（覆盖上次结果），也可以跳过写出计算结果（因为上次执行已经完整写出过计算结果了）<br>这样即可保证每次执行的计算结果，在 sink 这个层面，是 不重不丢 的 —— 即使中间发生过 1 次或以上的失效和恢复。</p>
<h3 id="小结：end-to-end-exactly-once-guarantees"><a href="#小结：end-to-end-exactly-once-guarantees" class="headerlink" title="小结：end-to-end exactly-once guarantees"></a>小结：end-to-end exactly-once guarantees</h3><p>所以在 Structured Streaming 里，我们总结下面的关系[4]：</p>
<p><img src="/images/10.png" alt="alt"><br>这里的 end-to-end 指的是，如果 source 选用类似 Kafka, HDFS 等，sink 选用类似 HDFS, MySQL 等，那么 Structured Streaming 将自动保证在 sink 里的计算结果是 exactly-once 的 —— Structured Streaming终于把过去需要使用者去维护的 sink 去重逻辑接盘过去了！:-)</p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/bigdata/">bigdata</a>
    </div>


      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/spark-Structured/" rel="tag">spark Structured</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>











  
    <article id="post-5" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a  href="/2019/06/11/5/" class="article-date">
      <time datetime="2019-06-11T14:33:55.000Z" itemprop="datePublished">2019-06-11</time>
</a>

    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a  class="article-title" href="/2019/06/11/5/">通过BulkLoad(MR)快速将海量数据导入到Hbase</a>
    </h1>
  


      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <h3 id="原始文件从mysq导出来的csv文件"><a href="#原始文件从mysq导出来的csv文件" class="headerlink" title="原始文件从mysq导出来的csv文件"></a>原始文件从mysq导出来的csv文件</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">503003676755886086,503003161271734273,1</span><br><span class="line">503003669797548035,503003161271734273,1</span><br><span class="line">503003568609964035,503003161271734273,1</span><br><span class="line">503003700512428038,503003161271734273,1</span><br><span class="line">503003764244881414,503003161271734273,1</span><br><span class="line">503003647634841604,503003161271734273,4</span><br><span class="line">503003747857739782,503003161271734273,7</span><br><span class="line">503003582082068480,503003161271734273,5</span><br><span class="line">503003646376542208,503003161271734273,3</span><br><span class="line">503003631474180105,503003161271734273,1</span><br></pre></td></tr></table></figure>

<h3 id="使用MR-对文件进行加盐操作根据MD5-region数量"><a href="#使用MR-对文件进行加盐操作根据MD5-region数量" class="headerlink" title="使用MR 对文件进行加盐操作根据MD5/region数量"></a>使用MR 对文件进行加盐操作根据MD5/region数量</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><span class="line">import org.slf4j.Logger;</span><br><span class="line">import org.slf4j.LoggerFactory;</span><br><span class="line"></span><br><span class="line">import java.security.MessageDigest;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line"> * 计数系统工具类</span><br><span class="line"> */</span><br><span class="line"></span><br><span class="line">public class CounterUtils &#123;</span><br><span class="line">	</span><br><span class="line">	</span><br><span class="line">	private static final Logger logger = LoggerFactory.getLogger(CounterUtils.class);</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">	/** region数量 */</span><br><span class="line">	private static Integer region_num = 4;</span><br><span class="line">	</span><br><span class="line">	/** salt前缀  */</span><br><span class="line">	private static String salt_prefix = <span class="string">"00"</span>;</span><br><span class="line">	</span><br><span class="line">	</span><br><span class="line">	</span><br><span class="line">	</span><br><span class="line">	/**</span><br><span class="line">	 * 为HBase rowkey产生salt值</span><br><span class="line">	 * @param key 原始计数键名</span><br><span class="line">	 * @<span class="built_in">return</span> salt值</span><br><span class="line">	 */</span><br><span class="line">	</span><br><span class="line">	public static String generateSalt(String key)&#123;</span><br><span class="line">		</span><br><span class="line">		Integer region_seq = Math.abs(generateMD5(key).hashCode()) % region_num;</span><br><span class="line">		</span><br><span class="line">		<span class="built_in">return</span> salt_prefix+String.valueOf(region_seq);</span><br><span class="line">		</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	</span><br><span class="line">	/**</span><br><span class="line">	 * 根据字符串产生MD5值</span><br><span class="line">	 * @param msg</span><br><span class="line">	 * @<span class="built_in">return</span>  字符串对应的MD5值</span><br><span class="line">	 */</span><br><span class="line">	</span><br><span class="line">	public static String generateMD5(String msg) &#123;</span><br><span class="line"></span><br><span class="line">		MessageDigest md5 = null;</span><br><span class="line"></span><br><span class="line">		try &#123;</span><br><span class="line"></span><br><span class="line">			md5 = MessageDigest.getInstance(<span class="string">"MD5"</span>);</span><br><span class="line"></span><br><span class="line">		&#125; catch (Exception e) &#123;</span><br><span class="line"></span><br><span class="line">			</span><br><span class="line">			logger.error(<span class="string">"产生MD5值报错"</span>,e);</span><br><span class="line"></span><br><span class="line">			<span class="built_in">return</span> <span class="string">""</span>;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		char[] charArray = msg.toCharArray();</span><br><span class="line">		byte[] byteArray = new byte[charArray.length];</span><br><span class="line"></span><br><span class="line">		<span class="keyword">for</span> (int i = 0; i &amp;lt; charArray.length; i++)</span><br><span class="line">			byteArray[i] = (byte) charArray[i];</span><br><span class="line"></span><br><span class="line">		byte[] md5Bytes = md5.digest(byteArray);</span><br><span class="line">		StringBuffer hexValue = new StringBuffer();</span><br><span class="line"></span><br><span class="line">		<span class="keyword">for</span> (int i = 0; i &amp;lt; md5Bytes.length; i++) &#123;</span><br><span class="line"></span><br><span class="line">			int val = ((int) md5Bytes[i]) &amp;amp; 0xff;</span><br><span class="line">			<span class="keyword">if</span> (val &amp;lt; 16)</span><br><span class="line">				hexValue.append(<span class="string">"0"</span>);</span><br><span class="line">			hexValue.append(Integer.toHexString(val));</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		<span class="built_in">return</span> hexValue.toString();</span><br><span class="line"></span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="加盐生成另一种文件MR程序"><a href="#加盐生成另一种文件MR程序" class="headerlink" title="加盐生成另一种文件MR程序"></a>加盐生成另一种文件MR程序</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br></pre></td><td class="code"><pre><span class="line">import java.io.DataInput;</span><br><span class="line">import java.io.DataOutput;</span><br><span class="line">import java.io.IOException;</span><br><span class="line">import java.net.URI;</span><br><span class="line"></span><br><span class="line">import org.apache.hadoop.conf.Configuration;</span><br><span class="line">import org.apache.hadoop.conf.Configured;</span><br><span class="line">import org.apache.hadoop.fs.FileSystem;</span><br><span class="line">import org.apache.hadoop.fs.Path;</span><br><span class="line">import org.apache.hadoop.io.LongWritable;</span><br><span class="line">import org.apache.hadoop.io.Text;</span><br><span class="line">import org.apache.hadoop.io.Writable;</span><br><span class="line">import org.apache.hadoop.mapreduce.Job;</span><br><span class="line">import org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line">import org.apache.hadoop.mapreduce.Reducer;</span><br><span class="line">import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line">import org.apache.hadoop.mapreduce.lib.input.TextInputFormat;</span><br><span class="line">import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line">import org.apache.hadoop.mapreduce.lib.output.TextOutputFormat;</span><br><span class="line">import org.apache.hadoop.util.GenericOptionsParser;</span><br><span class="line">import org.apache.hadoop.util.Tool;</span><br><span class="line">import org.apache.hadoop.util.ToolRunner;</span><br><span class="line"></span><br><span class="line">import com.jiatui.bigdata.util.CounterUtils;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">public class DateConversion extends Configured implements Tool &#123;</span><br><span class="line"></span><br><span class="line">	// 构建map类</span><br><span class="line">	public static class TestMap extends Mapper&amp;lt;LongWritable, Text, Text, TestWritable&amp;gt; &#123;</span><br><span class="line"></span><br><span class="line">		public void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException &#123;</span><br><span class="line"></span><br><span class="line">			// 根据$开始切割字段名</span><br><span class="line">			 String[] splited = value.toString().split(<span class="string">","</span>);</span><br><span class="line">			// 以第一个和第二个为rowkey值</span><br><span class="line">			String rowkey1=<span class="string">"LOOK_TIMES_"</span> + splited[1] + <span class="string">"_"</span> + splited[0];</span><br><span class="line">			</span><br><span class="line">		    String rowkey = CounterUtils.generateSalt(rowkey1)+rowkey1;</span><br><span class="line"></span><br><span class="line">			 Text k2 = new Text(rowkey);</span><br><span class="line">			// 第三个为value值</span><br><span class="line">			 TestWritable v2 = new TestWritable(splited[2]);</span><br><span class="line"></span><br><span class="line">			context.write(k2, v2);</span><br><span class="line"></span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	// 构建reduce类</span><br><span class="line">	public static class TestReduce extends Reducer&amp;lt;Text, TestWritable, Text, TestWritable&amp;gt; &#123;</span><br><span class="line"></span><br><span class="line">		public void reduce(Text k2, Iterable&amp;lt;TestWritable&amp;gt; v2s, Context context)</span><br><span class="line">				throws IOException, InterruptedException &#123;</span><br><span class="line"></span><br><span class="line">			String value;</span><br><span class="line"></span><br><span class="line">			// 循环所有的key值和values值</span><br><span class="line">			<span class="keyword">for</span> (TestWritable testWritable : v2s) &#123;</span><br><span class="line"></span><br><span class="line">				value = testWritable.value;</span><br><span class="line"></span><br><span class="line">				TestWritable v3 = new TestWritable(value);</span><br><span class="line">				context.write(k2, v3);</span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	// main方法启动</span><br><span class="line">	public static void main(String[] args) throws IOException, Exception &#123;</span><br><span class="line">		ToolRunner.run(new DateConversion(), args);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	public int run(String[] args) throws Exception &#123;</span><br><span class="line">		Configuration conf = new Configuration();</span><br><span class="line">		conf.set(<span class="string">"mapred.textoutputformat.separator"</span>, <span class="string">","</span>);</span><br><span class="line">	</span><br><span class="line">		String[] argArray = new GenericOptionsParser(conf, args).getRemainingArgs();</span><br><span class="line"></span><br><span class="line">		Job job = Job.getInstance(conf, <span class="string">"Test"</span>);</span><br><span class="line">		FileSystem fs = FileSystem.get(new URI(args[1]), conf);</span><br><span class="line">		fs.delete(new Path(args[1]));</span><br><span class="line">		job.setJarByClass(DateConversion.class);</span><br><span class="line">		job.setMapperClass(TestMap.class);</span><br><span class="line">		job.setMapOutputKeyClass(Text.class);</span><br><span class="line">		job.setMapOutputValueClass(TestWritable.class);</span><br><span class="line">		job.setReducerClass(TestReduce.class);</span><br><span class="line">		job.setOutputKeyClass(Text.class);</span><br><span class="line">		job.setOutputValueClass(TestWritable.class);</span><br><span class="line">		job.setInputFormatClass(TextInputFormat.class);</span><br><span class="line">		job.setOutputFormatClass(TextOutputFormat.class);</span><br><span class="line">		FileInputFormat.setInputPaths(job, new Path(args[0]));</span><br><span class="line">		FileOutputFormat.setOutputPath(job, new Path(args[1]));</span><br><span class="line">		job.waitForCompletion(<span class="literal">true</span>);</span><br><span class="line">		<span class="built_in">return</span> 0;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	static class TestWritable implements Writable &#123;</span><br><span class="line"></span><br><span class="line">		String value;</span><br><span class="line"></span><br><span class="line">		public TestWritable(String value) &#123;</span><br><span class="line">			this.value = value;</span><br><span class="line"></span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		// 无参构造方法public class UserBean implements Writable</span><br><span class="line">		// 这个应该是在自定义writable的时候需要注意，反射过程中需要调用无参构造。</span><br><span class="line">		public <span class="function"><span class="title">TestWritable</span></span>() &#123;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		public void readFields(DataInput <span class="keyword">in</span>) throws IOException &#123;</span><br><span class="line"></span><br><span class="line">			this.value = in.readUTF();</span><br><span class="line"></span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		public void write(DataOutput out) throws IOException &#123;</span><br><span class="line"></span><br><span class="line">			out.writeUTF(value);</span><br><span class="line"></span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		public String <span class="function"><span class="title">toString</span></span>() &#123;</span><br><span class="line">			<span class="built_in">return</span> value;</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="生成文件的形式为"><a href="#生成文件的形式为" class="headerlink" title="生成文件的形式为"></a>生成文件的形式为</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">000LOOK_TIMES_503003049082486784_503003525400236039,3</span><br><span class="line">000LOOK_TIMES_503003049082486784_503003558279393283,1</span><br><span class="line">001LOOK_TIMES_503003049099264000_503003517552689161,6</span><br><span class="line">002LOOK_TIMES_503003049099264000_503003586590937094,2</span><br><span class="line">002LOOK_TIMES_503003049099264000_503003611433799685,1</span><br><span class="line">002LOOK_TIMES_503003049099264000_503003638604505093,1</span><br><span class="line">003LOOK_TIMES_503003049099264000_503003646833725450,2</span><br><span class="line">003LOOK_TIMES_503003049099264000_503254267948171264,2</span><br><span class="line">003LOOK_TIMES_503003049099264000_504261308741332992,1</span><br><span class="line">003LOOK_TIMES_503003049099264000_505510528722927616,1</span><br></pre></td></tr></table></figure>

<h3 id="在进行另一个MR操作将生成的文件导入到Hbase表中"><a href="#在进行另一个MR操作将生成的文件导入到Hbase表中" class="headerlink" title="在进行另一个MR操作将生成的文件导入到Hbase表中"></a>在进行另一个MR操作将生成的文件导入到Hbase表中</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line">import java.io.IOException;</span><br><span class="line">import java.util.ArrayList;</span><br><span class="line">import java.util.List;</span><br><span class="line"></span><br><span class="line">import org.apache.hadoop.hbase.client.Put;</span><br><span class="line">import org.apache.hadoop.hbase.io.ImmutableBytesWritable;</span><br><span class="line">import org.apache.hadoop.hbase.util.Bytes;</span><br><span class="line">import org.apache.hadoop.io.LongWritable;</span><br><span class="line">import org.apache.hadoop.io.Text;</span><br><span class="line">import org.apache.hadoop.mapreduce.Mapper;</span><br><span class="line">import org.apache.log4j.Logger;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line"> * </span><br><span class="line">* &amp;lt;p&amp;gt;Title: GeneratorHFile&amp;lt;/p&amp;gt;  </span><br><span class="line">* &amp;lt;p&amp;gt;Description: 先把文件rowkey加盐成文件，根据rowkey ASC 排序 上传HDFS(排序在hive总进行)</span><br><span class="line">* insert overwrite  directory <span class="string">'/dmp_operator1/test/'</span></span><br><span class="line">  row format delimited</span><br><span class="line">  fields terminated by <span class="string">','</span></span><br><span class="line">  select * from <span class="built_in">test</span>  order by id asc;</span><br><span class="line">* &amp;lt;/p&amp;gt;  </span><br><span class="line">* @author zhangshuai  </span><br><span class="line">* @date 2018年12月19日</span><br><span class="line"> */</span><br><span class="line">public class GeneratorHFile extends Mapper&amp;lt;LongWritable, Text, ImmutableBytesWritable, Put&amp;gt; &#123;</span><br><span class="line">	</span><br><span class="line">	private static Logger logger = Logger.getLogger(GeneratorHFile.class); </span><br><span class="line">       </span><br><span class="line"></span><br><span class="line">	</span><br><span class="line">	protected void map(LongWritable Key, Text Value,</span><br><span class="line">			Mapper&amp;lt;LongWritable, Text, ImmutableBytesWritable, Put&amp;gt;.Context context)</span><br><span class="line">			throws IOException, InterruptedException &#123;</span><br><span class="line">		</span><br><span class="line">		//切分导入的数据</span><br><span class="line">		String Values=Value.toString();</span><br><span class="line">		String[] Lines=Values.split(<span class="string">","</span>);</span><br><span class="line">		</span><br><span class="line">		</span><br><span class="line">		String Rowkey=Lines[0];</span><br><span class="line">		</span><br><span class="line">		Long ColValue=Long.valueOf(Lines[1]);</span><br><span class="line">		//拼装rowkey和put;</span><br><span class="line">		ImmutableBytesWritable PutRowkey=new ImmutableBytesWritable(Bytes.toBytes(Rowkey));</span><br><span class="line">		Put put=new Put(Bytes.toBytes(Rowkey));</span><br><span class="line">		put.addColumn(Bytes.toBytes(<span class="string">"cf1"</span>), Bytes.toBytes(<span class="string">"cnt"</span>), Bytes.toBytes(ColValue));</span><br><span class="line">		</span><br><span class="line">		context.write(PutRowkey,put);</span><br><span class="line">		</span><br><span class="line">		</span><br><span class="line">		</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br></pre></td><td class="code"><pre><span class="line">package com.jiatui.bigdata;</span><br><span class="line"></span><br><span class="line">import java.io.IOException;</span><br><span class="line"></span><br><span class="line">import org.apache.hadoop.conf.Configuration;</span><br><span class="line">import org.apache.hadoop.fs.Path;</span><br><span class="line">import org.apache.hadoop.hbase.HBaseConfiguration;</span><br><span class="line">import org.apache.hadoop.hbase.TableName;</span><br><span class="line">import org.apache.hadoop.hbase.client.Admin;</span><br><span class="line">import org.apache.hadoop.hbase.client.Connection;</span><br><span class="line">import org.apache.hadoop.hbase.client.ConnectionFactory;</span><br><span class="line">import org.apache.hadoop.hbase.client.HTable;</span><br><span class="line">import org.apache.hadoop.hbase.client.Put;</span><br><span class="line">import org.apache.hadoop.hbase.client.Table;</span><br><span class="line">import org.apache.hadoop.hbase.io.ImmutableBytesWritable;</span><br><span class="line">import org.apache.hadoop.hbase.mapreduce.HFileOutputFormat2;</span><br><span class="line">import org.apache.hadoop.hbase.mapreduce.LoadIncrementalHFiles;</span><br><span class="line">import org.apache.hadoop.mapreduce.Job;</span><br><span class="line">import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;</span><br><span class="line">import org.apache.hadoop.mapreduce.lib.input.TextInputFormat;</span><br><span class="line">import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;</span><br><span class="line">import org.apache.hadoop.security.UserGroupInformation;</span><br><span class="line"></span><br><span class="line">import com.jiatui.bigdata.util.ScheduleKerBeros;</span><br><span class="line"></span><br><span class="line">public class GenerateHFileDriver &#123;</span><br><span class="line"></span><br><span class="line">	public static void main(String[] args) throws Exception &#123;</span><br><span class="line"></span><br><span class="line">		ScheduleKerBeros scheduleKerBeros = new ScheduleKerBeros();</span><br><span class="line">		scheduleKerBeros.scheduled();</span><br><span class="line"></span><br><span class="line">		/**</span><br><span class="line">		 * 获取Hbase配置，创建连接到目标表，表在Shell中已经创建好，建表语句create</span><br><span class="line">		 * <span class="string">'counter_sys.counter_tbl'</span>,<span class="string">'cf1'</span>，这里注意HBase对大小写很敏感</span><br><span class="line">		 */</span><br><span class="line"></span><br><span class="line">		Configuration conf = HBaseConfiguration.create();</span><br><span class="line">		conf.set(<span class="string">"hbase.zookeeper.quorum"</span>, <span class="string">"192.168.103.3,192.168.103.4,192.168.103.5"</span>);</span><br><span class="line">		conf.set(<span class="string">"hbase.zookeeper.property.clientPort"</span>, <span class="string">"2181"</span>);</span><br><span class="line">		conf.addResource(<span class="string">"/home/dmp_operator1/tickets/hbase-site.xml"</span>);</span><br><span class="line">		conf.addResource(<span class="string">"/home/dmp_operator1/tickets/core-site.xml"</span>);</span><br><span class="line">		conf.addResource(<span class="string">"/home/dmp_operator1/tickets/hdfs-site.xml"</span>);</span><br><span class="line">		conf.set(<span class="string">"zookeeper.znode.parent"</span>, <span class="string">"/hbase-secure"</span>);</span><br><span class="line"></span><br><span class="line">		conf.set(<span class="string">"mapreduce.input.fileinputformat.split.maxsize"</span>, String.valueOf(64 * 1024 * 1024));</span><br><span class="line">		conf.set(<span class="string">"mapred.min.split.size"</span>, String.valueOf(64 * 1024 * 1024));</span><br><span class="line">		conf.set(<span class="string">"mapreduce.input.fileinputformat.split.minsize.per.node"</span>, String.valueOf(64 * 1024 * 1024));</span><br><span class="line">		conf.set(<span class="string">"mapreduce.input.fileinputformat.split.minsize.per.rack"</span>, String.valueOf(64 * 1024 * 1024));</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">		Connection conn = ConnectionFactory.createConnection(conf);</span><br><span class="line">		Table table = conn.getTable(TableName.valueOf(<span class="string">"counter_sys:counter_tbl"</span>));</span><br><span class="line">		Admin admin = conn.getAdmin();</span><br><span class="line"></span><br><span class="line">		final String InputFile = <span class="string">"hdfs://DATASEA/user/hbase/test/input"</span>;</span><br><span class="line">		final String OutputFile = <span class="string">"hdfs://DATASEA/user/hbase/test/output"</span>;</span><br><span class="line">		final Path OutputPath = new Path(OutputFile);</span><br><span class="line"></span><br><span class="line">		// 设置相关类名</span><br><span class="line">		Job job = Job.getInstance(conf, <span class="string">"counter_sys:counter_tbl"</span>);</span><br><span class="line">		job.setJarByClass(GenerateHFileDriver.class);</span><br><span class="line">		job.setMapperClass(GeneratorHFile.class);</span><br><span class="line">		job.setMapOutputKeyClass(ImmutableBytesWritable.class);</span><br><span class="line">		job.setMapOutputValueClass(Put.class);</span><br><span class="line"></span><br><span class="line">		// 设置文件的输入路径和输出路径</span><br><span class="line">		job.setInputFormatClass(TextInputFormat.class);</span><br><span class="line">		job.setOutputFormatClass(HFileOutputFormat2.class);</span><br><span class="line">		FileInputFormat.setInputPaths(job, InputFile);</span><br><span class="line">		FileOutputFormat.setOutputPath(job, OutputPath);</span><br><span class="line"></span><br><span class="line">		// 配置MapReduce作业，以执行增量加载到给定表中。</span><br><span class="line">		HFileOutputFormat2.configureIncrementalLoad(job, table,</span><br><span class="line">				conn.getRegionLocator(TableName.valueOf(<span class="string">"counter_sys:counter_tbl"</span>)));</span><br><span class="line"></span><br><span class="line">		// MapReduce作业完成，告知RegionServers在哪里找到这些文件,将文件加载到HBase中</span><br><span class="line">		<span class="keyword">if</span> (job.waitForCompletion(<span class="literal">true</span>)) &#123;</span><br><span class="line">			LoadIncrementalHFiles Loader = new LoadIncrementalHFiles(conf);</span><br><span class="line">			Loader.doBulkLoad(OutputPath, admin, table,</span><br><span class="line">					conn.getRegionLocator(TableName.valueOf(<span class="string">"counter_sys:counter_tbl"</span>)));</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line">import com.sun.tools.extcheck.Main;</span><br><span class="line">import org.apache.hadoop.conf.Configuration;</span><br><span class="line">import org.apache.hadoop.hbase.HBaseConfiguration;</span><br><span class="line">import org.apache.hadoop.hbase.HColumnDescriptor;</span><br><span class="line">import org.apache.hadoop.hbase.HTableDescriptor;</span><br><span class="line">import org.apache.hadoop.hbase.TableName;</span><br><span class="line">import org.apache.hadoop.hbase.client.ConnectionFactory;</span><br><span class="line">import org.apache.hadoop.hbase.client.HBaseAdmin;</span><br><span class="line">import org.apache.hadoop.security.UserGroupInformation;</span><br><span class="line">import org.slf4j.Logger;</span><br><span class="line">import org.slf4j.LoggerFactory;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">import java.time.LocalTime;</span><br><span class="line"></span><br><span class="line">/**</span><br><span class="line"> * </span><br><span class="line"> * &amp;lt;p&amp;gt;</span><br><span class="line"> * Title: ScheduleTest</span><br><span class="line"> * &amp;lt;/p&amp;gt;</span><br><span class="line"> * &amp;lt;p&amp;gt;</span><br><span class="line"> * Description:</span><br><span class="line"> * &amp;lt;/p&amp;gt;</span><br><span class="line"> * </span><br><span class="line"> * @author zhangshuai</span><br><span class="line"> * @date 2018年12月6日</span><br><span class="line"> */</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">public class ScheduleKerBeros &#123;</span><br><span class="line">	private static final Logger logger = LoggerFactory.getLogger(ScheduleKerBeros.class);</span><br><span class="line"></span><br><span class="line">	/**</span><br><span class="line">	 * </span><br><span class="line">	 * &amp;lt;p&amp;gt;Title: scheduled&amp;lt;/p&amp;gt;  </span><br><span class="line">	 * &amp;lt;p&amp;gt;Description: &amp;lt;/p&amp;gt;</span><br><span class="line">	 */</span><br><span class="line"></span><br><span class="line">	public void <span class="function"><span class="title">scheduled</span></span>() &#123;</span><br><span class="line"></span><br><span class="line">		logger.info(<span class="string">"开始授权..."</span>);</span><br><span class="line">	    //System.setProperty(<span class="string">"java.security.krb5.conf"</span>, this.getClass().getResource(<span class="string">"/krb5.conf"</span>).getPath());</span><br><span class="line">	    System.setProperty(<span class="string">"java.security.krb5.conf"</span>, <span class="string">"/etc/krb5.conf"</span>);</span><br><span class="line">		try &#123;</span><br><span class="line">			logger.info(<span class="string">"授权中1..."</span>);</span><br><span class="line">			UserGroupInformation.loginUserFromKeytab(<span class="string">"hbase/dev-bg-m01@DATASEA.COM"</span>,<span class="string">"/etc/security/keytabs/hbase.service.keytab"</span>);</span><br><span class="line">		//UserGroupInformation.loginUserFromKeytab(<span class="string">"dmp_operator1@DATASEA.COM"</span>,this.getClass().getResource(<span class="string">"/dmp_operator1.keytab"</span>).getPath());</span><br><span class="line">			</span><br><span class="line">			</span><br><span class="line">			logger.info(<span class="string">"授权成功1..."</span>);</span><br><span class="line"></span><br><span class="line">		&#125; catch (Exception e) &#123;</span><br><span class="line">			</span><br><span class="line">		&#125;</span><br><span class="line">	        </span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	</span><br><span class="line">	</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>



      
    </div>
    
    <div class="article-info article-info-index">
      
      
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/bigdata/">bigdata</a>
    </div>


      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Hbase/" rel="tag">Hbase</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>











  
    <article id="post-7" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a  href="/2019/05/02/7/" class="article-date">
      <time datetime="2019-05-02T03:01:24.000Z" itemprop="datePublished">2019-05-02</time>
</a>

    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a  class="article-title" href="/2019/05/02/7/">Spring mvc 框架定时刷新kerberos认证票据</a>
    </h1>
  


      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">package com.XXX.counter.listener;</span><br><span class="line"></span><br><span class="line">import javax.servlet.ServletContextEvent;</span><br><span class="line">import javax.servlet.ServletContextListener;</span><br><span class="line">import java.util.Timer;  </span><br><span class="line">public class TicketScanerListener implements ServletContextListener &#123;</span><br><span class="line">	private Object lock = new Object();  </span><br><span class="line">	public void contextDestroyed(ServletContextEvent arg0) &#123;</span><br><span class="line">		System.out.println(<span class="string">"web应用关闭..."</span>);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	public void contextInitialized(ServletContextEvent arg0) &#123;</span><br><span class="line">		System.out.println(<span class="string">"web应用初始化..."</span>);</span><br><span class="line">		// 创建定时器</span><br><span class="line">		Timer timer = new Timer();</span><br><span class="line">		// 每隔30秒就定时执行任务</span><br><span class="line">		timer.schedule(new TicketScanerTask(lock), 0, 1000 * 1000);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">package com.xxx.counter.listener;</span><br><span class="line">  </span><br><span class="line">import java.util.TimerTask;</span><br><span class="line"></span><br><span class="line">import org.apache.log4j.Logger;</span><br><span class="line">import org.apache.hadoop.conf.Configuration;</span><br><span class="line">import org.apache.hadoop.hbase.HBaseConfiguration;</span><br><span class="line">import org.apache.hadoop.hbase.client.Connection;</span><br><span class="line">import org.apache.hadoop.hbase.client.ConnectionFactory;</span><br><span class="line">import org.apache.hadoop.security.UserGroupInformation;  </span><br><span class="line">/** </span><br><span class="line"> * 定时器，定义定时任务的具体内容 </span><br><span class="line"> */  </span><br><span class="line">public class TicketScanerTask extends TimerTask&#123;  </span><br><span class="line">	private static Logger logger = Logger.getLogger(TicketScanerTask.class); </span><br><span class="line">    // 存储传递过来的锁  </span><br><span class="line">    private Object lock;  </span><br><span class="line">    // 构造方法  </span><br><span class="line">    TicketScanerTask( Object lock)&#123;  </span><br><span class="line">        this.lock = lock;  </span><br><span class="line">    &#125;  </span><br><span class="line">    </span><br><span class="line">    private static Configuration conf = null;</span><br><span class="line">    public static String principal = <span class="string">"dmp_operator1@DATASEA.COM"</span>;</span><br><span class="line">    public static String keytabPath = <span class="string">"dmp_operator1.keytab"</span>;</span><br><span class="line">    @Override  </span><br><span class="line">    public void  <span class="function"><span class="title">run</span></span>() &#123;  </span><br><span class="line">        // 考虑到多线程的情况，这里必须要同步  </span><br><span class="line">        synchronized (lock)&#123;  </span><br><span class="line"></span><br><span class="line">        	logger.info(<span class="string">"TicketScanerTask......"</span>);</span><br><span class="line"></span><br><span class="line">            	System.setProperty(<span class="string">"java.security.krb5.conf"</span>,this.getClass().getResource(<span class="string">"/krb5.conf"</span>).getPath());</span><br><span class="line">            </span><br><span class="line">                try &#123;</span><br><span class="line">                    UserGroupInformation.loginUserFromKeytab(<span class="string">"dmp_operator1@DATASEA.COM"</span>, this.getClass().getResource(<span class="string">"/dmp_operator1.keytab"</span>).getPath());</span><br><span class="line"></span><br><span class="line">                &#125; catch (Exception e) &#123;</span><br><span class="line">    			// TODO Auto-generated catch block</span><br><span class="line">    			e.printStackTrace();</span><br><span class="line">    			logger.error(<span class="string">"授权失败..."</span>);</span><br><span class="line">    		&#125;</span><br><span class="line">              </span><br><span class="line">        	</span><br><span class="line">        &#125;  </span><br><span class="line">    &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&lt;listener&gt;</span><br><span class="line">    &lt;listener-class&gt;com.xxx.counter.listener.TicketScanerListener&lt;/listener-class&gt;</span><br><span class="line">  &lt;/listener&gt;</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">package com.xxx.counter.util;</span><br><span class="line"></span><br><span class="line">import java.io.IOException;</span><br><span class="line"></span><br><span class="line">import org.apache.hadoop.conf.Configuration;</span><br><span class="line">import org.apache.hadoop.hbase.HBaseConfiguration;</span><br><span class="line">import org.apache.hadoop.hbase.client.Connection;</span><br><span class="line">import org.apache.hadoop.hbase.client.ConnectionFactory;</span><br><span class="line">import org.slf4j.Logger;</span><br><span class="line">import org.slf4j.LoggerFactory;</span><br><span class="line"></span><br><span class="line">public class HbaseConnection &#123;</span><br><span class="line">	private static final Logger logger = LoggerFactory.getLogger(HbaseConnection.class);</span><br><span class="line"></span><br><span class="line">	public static Configuration conf = null;</span><br><span class="line">	public static Connection connection = null;</span><br><span class="line">	</span><br><span class="line">	public Connection getConnection () throws IOException &#123;</span><br><span class="line">		conf = HBaseConfiguration.create();</span><br><span class="line"></span><br><span class="line">	    conf.addResource(this.getClass().getResource(<span class="string">"/hbase-site.xml"</span>).getPath());</span><br><span class="line">	    conf.addResource(this.getClass().getResource(<span class="string">"/core-site.xml"</span>).getPath());</span><br><span class="line">	    conf.addResource(this.getClass().getResource(<span class="string">"/hdfs-site.xml"</span>).getPath());</span><br><span class="line">	    conf.set(<span class="string">"hbase.zookeeper.quorum"</span>, <span class="string">"192.168.103.3,192.168.103.4,192.168.103.5"</span>);</span><br><span class="line">	    conf.set(<span class="string">"hbase.zookeeper.property.clientPort"</span>, <span class="string">"2181"</span>);</span><br><span class="line">	    conf.set(<span class="string">"zookeeper.znode.parent"</span>, <span class="string">"/hbase-secure"</span>);</span><br><span class="line">	    conf.setLong(<span class="string">"hbase.rpc.timeout"</span>, 30000);</span><br><span class="line">	    connection = ConnectionFactory.createConnection(conf);</span><br><span class="line">	    <span class="built_in">return</span> connection;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


      
    </div>
    
    <div class="article-info article-info-index">
      
      
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/java/">java</a>
    </div>


      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/kerberos/" rel="tag">kerberos</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>











  
    <article id="post-3" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a  href="/2019/04/02/3/" class="article-date">
      <time datetime="2019-04-02T03:01:24.000Z" itemprop="datePublished">2019-04-02</time>
</a>

    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a  class="article-title" href="/2019/04/02/3/">Spark Scala 获取自然日 属于每周的第一天和每周的最后一天，每月的第一天和每月的最后一天</a>
    </h1>
  


      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <h3 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br></pre></td><td class="code"><pre><span class="line">package com.xxxx.bigdata</span><br><span class="line">import java.util.Calendar</span><br><span class="line">import java.text.SimpleDateFormat</span><br><span class="line">import org.apache.spark.sql.Row</span><br><span class="line">import scala.collection.mutable.ArrayBuffer</span><br><span class="line">import org.apache.spark.SparkContext</span><br><span class="line">import org.apache.spark.SparkConf</span><br><span class="line">import org.apache.spark.sql.hive.HiveContext</span><br><span class="line">import org.apache.spark.sql.types.StructType</span><br><span class="line">import org.apache.spark.sql.types.StructField</span><br><span class="line">import org.apache.spark.sql.types.StringType</span><br><span class="line"></span><br><span class="line">object Date_week_month &#123;</span><br><span class="line">  def getNowWeekStart(logdate: String) = &#123;</span><br><span class="line">    var period: String = <span class="string">""</span></span><br><span class="line">    var cal: Calendar = Calendar.getInstance();</span><br><span class="line">    var df: SimpleDateFormat = new SimpleDateFormat(<span class="string">"yyyy-MM-dd"</span>);</span><br><span class="line"></span><br><span class="line">    cal.setTime(df.parse(logdate))</span><br><span class="line"></span><br><span class="line">    var d = 0</span><br><span class="line">    <span class="keyword">if</span> (cal.get(Calendar.DAY_OF_WEEK) == 1) &#123;</span><br><span class="line">      d = -6</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      d = 2 - cal.get(Calendar.DAY_OF_WEEK)</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    cal.add(Calendar.DAY_OF_WEEK, d)</span><br><span class="line"></span><br><span class="line">    val startdate = new SimpleDateFormat(<span class="string">"yyyy-MM-dd"</span>).format(cal.getTime())</span><br><span class="line"></span><br><span class="line">    cal.add(Calendar.DAY_OF_WEEK, 6)</span><br><span class="line"></span><br><span class="line">    val enddate = new SimpleDateFormat(<span class="string">"yyyy-MM-dd"</span>).format(cal.getTime())</span><br><span class="line"></span><br><span class="line">    (startdate, enddate)</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  def getNowMonthStart(logdate: String) = &#123;</span><br><span class="line">    var cal: Calendar = Calendar.getInstance();</span><br><span class="line">    var df: SimpleDateFormat = new SimpleDateFormat(<span class="string">"yyyy-MM-dd"</span>);</span><br><span class="line">    cal.setTime(df.parse(logdate))</span><br><span class="line">    cal.set(Calendar.DATE, 1)</span><br><span class="line">    val monthstart = df.format(cal.getTime())</span><br><span class="line"></span><br><span class="line">    cal.set(Calendar.DATE, 1)</span><br><span class="line">    cal.roll(Calendar.DATE, -1)</span><br><span class="line">    val monthend = df.format(cal.getTime())</span><br><span class="line"></span><br><span class="line">    (monthstart, monthend)</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">  def main(args: Array[String]): Unit = &#123;</span><br><span class="line"></span><br><span class="line">    val conf = new SparkConf().setAppName(<span class="string">"test"</span>).setMaster(<span class="string">"local"</span>)</span><br><span class="line">    conf.set(<span class="string">"spark.default.parallelism"</span>, <span class="string">"200"</span>)</span><br><span class="line">    conf.set(<span class="string">"spark.sql.shuffle.partitions"</span>, <span class="string">"200"</span>)</span><br><span class="line">    conf.set(<span class="string">"spark.serializer"</span>, <span class="string">"org.apache.spark.serializer.KryoSerializer"</span>)</span><br><span class="line">    conf.set(<span class="string">"zookeeper.znode.parent"</span>, <span class="string">"/hbase-secure"</span>)</span><br><span class="line">    val sc = new SparkContext(conf)</span><br><span class="line">    val hiveContext = new HiveContext(sc)</span><br><span class="line"></span><br><span class="line">    hiveContext.setConf(<span class="string">"hive.exec.dynamic.partition"</span>, <span class="string">"true"</span>)</span><br><span class="line">    hiveContext.setConf(<span class="string">"hive.exec.dynamic.partition.mode"</span>, <span class="string">"nonstrict"</span>)</span><br><span class="line">    hiveContext.setConf(<span class="string">"hive.exec.max.dynamic.partitions.pernode"</span>, <span class="string">"2000"</span>)</span><br><span class="line">    hiveContext.setConf(<span class="string">"hive.exec.max.dynamic.partitions"</span>, <span class="string">"5000"</span>)</span><br><span class="line">    sc.setLogLevel(<span class="string">"ERROR"</span>)</span><br><span class="line">    val startTime = <span class="string">"2018-01-01"</span></span><br><span class="line"></span><br><span class="line">    val endTime = <span class="string">"2021-12-31"</span></span><br><span class="line"></span><br><span class="line">    val dateFormat = new SimpleDateFormat(<span class="string">"yyyy-MM-dd"</span>)</span><br><span class="line"></span><br><span class="line">    val dateFiled = Calendar.DAY_OF_MONTH</span><br><span class="line"></span><br><span class="line">    var beginDate = dateFormat.parse(startTime)</span><br><span class="line"></span><br><span class="line">    val endDate = dateFormat.parse(endTime)</span><br><span class="line"></span><br><span class="line">    val calendar = Calendar.getInstance()</span><br><span class="line"></span><br><span class="line">    calendar.setTime(beginDate)</span><br><span class="line"></span><br><span class="line">    val dateArray: ArrayBuffer[String] = ArrayBuffer()</span><br><span class="line"></span><br><span class="line">    val data = new ArrayBuffer[Row]</span><br><span class="line">    <span class="keyword">while</span> (beginDate.compareTo(endDate) &lt;= 0) &#123;</span><br><span class="line"></span><br><span class="line">      val login_time = dateFormat.format(beginDate)</span><br><span class="line"></span><br><span class="line">      val starttime = getNowWeekStart(login_time)._1</span><br><span class="line">      val endtime = getNowWeekStart(login_time)._2</span><br><span class="line"></span><br><span class="line">      val monthstart = getNowMonthStart(login_time)._1</span><br><span class="line">      val monthend = getNowMonthStart(login_time)._2</span><br><span class="line"></span><br><span class="line">      data += Row(login_time, starttime, endtime, monthstart, monthend)</span><br><span class="line"></span><br><span class="line">      calendar.add(dateFiled, 1)</span><br><span class="line">      beginDate = calendar.getTime</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    val rdd = sc.parallelize(data)</span><br><span class="line"></span><br><span class="line">    val stuct = StructType(</span><br><span class="line">      Array(</span><br><span class="line">        StructField(<span class="string">"login_time"</span>, StringType),</span><br><span class="line">        StructField(<span class="string">"starttime"</span>, StringType),</span><br><span class="line">        StructField(<span class="string">"endtime"</span>, StringType),</span><br><span class="line">        StructField(<span class="string">"monthstart"</span>, StringType),</span><br><span class="line">        StructField(<span class="string">"monthend"</span>, StringType)))</span><br><span class="line"></span><br><span class="line">    val test1 = hiveContext.createDataFrame(rdd, stuct)</span><br><span class="line"></span><br><span class="line">    val tmpTable = <span class="string">"dateTable"</span></span><br><span class="line"></span><br><span class="line">    test1.registerTempTable(tmpTable)</span><br><span class="line"></span><br><span class="line">    val sql = s<span class="string">""</span><span class="string">"</span></span><br><span class="line"><span class="string">      select count(*) from </span></span><br><span class="line"><span class="string">		      <span class="variable">$tmpTable</span> </span></span><br><span class="line"><span class="string">      "</span><span class="string">""</span></span><br><span class="line"></span><br><span class="line">    println(<span class="string">"sql = "</span> + sql)</span><br><span class="line"></span><br><span class="line">    hiveContext.sql(sql).show();</span><br><span class="line"></span><br><span class="line">    sc.stop()</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="Hive-SQL-实现以上方法先循环取出，日期之间所有的日期"><a href="#Hive-SQL-实现以上方法先循环取出，日期之间所有的日期" class="headerlink" title="Hive SQL 实现以上方法先循环取出，日期之间所有的日期"></a>Hive SQL 实现以上方法先循环取出，日期之间所有的日期</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">START_DAY=<span class="string">'2018-01-01'</span></span><br><span class="line">END_DAY=<span class="string">'2021-12-31'</span></span><br><span class="line"> </span><br><span class="line">initSec=`date -d <span class="variable">$START_DAY</span> +%s`</span><br><span class="line">finiSec=`date -d <span class="variable">$END_DAY</span> +%s`</span><br><span class="line"><span class="keyword">for</span> ((i=<span class="variable">$initSec</span>; i &lt;=<span class="variable">$finiSec</span>; i+=24 * 3600 ));<span class="keyword">do</span></span><br><span class="line">        cur_day=`date -d <span class="string">"1970-1-1 UTC <span class="variable">$i</span> seconds"</span> +%F`</span><br><span class="line">        <span class="built_in">echo</span> <span class="string">"<span class="variable">$cur_day</span>,,,,"</span>&gt;&gt; testa</span><br><span class="line"> </span><br><span class="line"><span class="keyword">done</span></span><br></pre></td></tr></table></figure>

<h3 id="生成了-这样的文件"><a href="#生成了-这样的文件" class="headerlink" title="生成了 这样的文件"></a>生成了 这样的文件</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">2018-01-01,,,,</span><br><span class="line">2018-01-02,,,,</span><br><span class="line">2018-01-03,,,,</span><br><span class="line">2018-01-04,,,,</span><br><span class="line">2018-01-05,,,,</span><br><span class="line">2018-01-06,,,,</span><br><span class="line">2018-01-07,,,,</span><br><span class="line">.............</span><br></pre></td></tr></table></figure>
<h3 id="然后load到Hive表中"><a href="#然后load到Hive表中" class="headerlink" title="然后load到Hive表中"></a>然后load到Hive表中</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE <span class="built_in">test</span> (dt String,WEEK_START string,WEEK_END string,MONTH_START string,MONTH_END string)row format delimited fields TERMINATED BY <span class="string">','</span>;</span><br></pre></td></tr></table></figure>

<h3 id="执行SQL"><a href="#执行SQL" class="headerlink" title="执行SQL"></a>执行SQL</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">insert overwrite table <span class="built_in">test</span> select  dt,date_sub(dt,cast(date_format(dt,<span class="string">'u'</span>) as int)-1) as start_time,</span><br><span class="line">date_sub(dt,cast(date_format(dt,<span class="string">'u'</span>) as int)-7) as end_time,trunc(dt,<span class="string">'MM'</span>),last_day(dt) from <span class="built_in">test</span></span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">| 2021-02-24  | 2021-02-22  | 2021-02-28  | 2021-02-01  | 2021-02-28  |</span><br><span class="line">| 2021-02-25  | 2021-02-22  | 2021-02-28  | 2021-02-01  | 2021-02-28  |</span><br><span class="line">| 2021-02-26  | 2021-02-22  | 2021-02-28  | 2021-02-01  | 2021-02-28  |</span><br><span class="line">| 2021-02-27  | 2021-02-22  | 2021-02-28  | 2021-02-01  | 2021-02-28  |</span><br><span class="line">| 2021-02-28  | 2021-02-22  | 2021-02-28  | 2021-02-01  | 2021-02-28  |</span><br><span class="line">| 2021-03-01  | 2021-03-01  | 2021-03-07  | 2021-03-01  | 2021-03-31  |</span><br><span class="line">| 2021-03-02  | 2021-03-01  | 2021-03-07  | 2021-03-01  | 2021-03-31  |</span><br><span class="line">| 2021-03-03  | 2021-03-01  | 2021-03-07  | 2021-03-01  | 2021-03-31  |</span><br><span class="line">| 2021-03-04  | 2021-03-01  | 2021-03-07  | 2021-03-01  | 2021-03-31  |</span><br><span class="line">| 2021-03-05  | 2021-03-01  | 2021-03-07  | 2021-03-01  | 2021-03-31  |</span><br><span class="line">| 2021-03-06  | 2021-03-01  | 2021-03-07  | 2021-03-01  | 2021-03-31  |</span><br><span class="line">| 2021-03-07  | 2021-03-01  | 2021-03-07  | 2021-03-01  | 2021-03-31  |</span><br><span class="line">| 2021-03-08  | 2021-03-08  | 2021-03-14  | 2021-03-01  | 2021-03-31  |</span><br><span class="line">| 2021-03-09  | 2021-03-08  | 2021-03-14  | 2021-03-01  | 2021-03-31  |</span><br><span class="line">| 2021-03-10  | 2021-03-08  | 2021-03-14  | 2021-03-01  | 2021-03-31  |</span><br><span class="line">| 2021-03-11  | 2021-03-08  | 2021-03-14  | 2021-03-01  | 2021-03-31  |</span><br><span class="line">| 2021-03-12  | 2021-03-08  | 2021-03-14  | 2021-03-01  | 2021-03-31  |</span><br><span class="line">| 2021-03-13  | 2021-03-08  | 2021-03-14  | 2021-03-01  | 2021-03-31  |</span><br><span class="line">| 2021-03-14  | 2021-03-08  | 2021-03-14  | 2021-03-01  | 2021-03-31  |</span><br><span class="line">| 2021-03-15  | 2021-03-15  | 2021-03-21  | 2021-03-01  | 2021-03-31  |</span><br><span class="line">| 2021-03-16  | 2021-03-15  | 2021-03-21  | 2021-03-01  | 2021-03-31  |</span><br><span class="line">| 2021-03-17  | 2021-03-15  | 2021-03-21  | 2021-03-01  | 2021-03-31  |</span><br><span class="line">| 2021-03-18  | 2021-03-15  | 2021-03-21  | 2021-03-01  | 2021-03-31  |</span><br><span class="line">| 2021-03-19  | 2021-03-15  | 2021-03-21  | 2021-03-01  | 2021-03-31  |</span><br><span class="line">| 2021-03-20  | 2021-03-15  | 2021-03-21  | 2021-03-01  | 2021-03-31  |</span><br><span class="line">| 2021-03-21  | 2021-03-15  | 2021-03-21  | 2021-03-01  | 2021-03-31  |</span><br><span class="line">| 2021-03-22  | 2021-03-22  | 2021-03-28  | 2021-03-01  | 2021-03-31  |</span><br><span class="line">| 2021-03-23  | 2021-03-22  | 2021-03-28  | 2021-03-01  | 2021-03-31  |</span><br><span class="line">| 2021-03-24  | 2021-03-22  | 2021-03-28  | 2021-03-01  | 2021-03-31  |</span><br><span class="line">| 2021-03-25  | 2021-03-22  | 2021-03-28  | 2021-03-01  | 2021-03-31  |</span><br><span class="line">| 2021-03-26  | 2021-03-22  | 2021-03-28  | 2021-03-01  | 2021-03-31  |</span><br><span class="line">| 2021-03-27  | 2021-03-22  | 2021-03-28  | 2021-03-01  | 2021-03-31  |</span><br><span class="line">| 2021-03-28  | 2021-03-22  | 2021-03-28  | 2021-03-01  | 2021-03-31  |</span><br><span class="line">| 2021-03-29  | 2021-03-29  | 2021-04-04  | 2021-03-01  | 2021-03-31  |</span><br><span class="line">| 2021-03-30  | 2021-03-29  | 2021-04-04  | 2021-03-01  | 2021-03-31  |</span><br><span class="line">| 2021-03-31  | 2021-03-29  | 2021-04-04  | 2021-03-01  | 2021-03-31  |</span><br><span class="line">| 2021-04-01  | 2021-03-29  | 2021-04-04  | 2021-04-01  | 2021-04-30  |</span><br></pre></td></tr></table></figure>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/bigdata/">bigdata</a>
    </div>


      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/spark/" rel="tag">spark</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>











  
    <article id="post-8" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a  href="/2019/04/02/8/" class="article-date">
      <time datetime="2019-04-02T03:01:24.000Z" itemprop="datePublished">2019-04-02</time>
</a>

    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a  class="article-title" href="/2019/04/02/8/">Spark1.X操作DataFrame示例</a>
    </h1>
  


      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">&#123;<span class="string">"id"</span>:1, <span class="string">"name"</span>:<span class="string">"Ganymede"</span>, <span class="string">"age"</span>:32&#125;</span><br><span class="line"></span><br><span class="line">&#123;<span class="string">"id"</span>:2, <span class="string">"name"</span>:<span class="string">"Lilei"</span>, <span class="string">"age"</span>:19&#125;</span><br><span class="line"></span><br><span class="line">&#123;<span class="string">"id"</span>:3, <span class="string">"name"</span>:<span class="string">"Lily"</span>, <span class="string">"age"</span>:25&#125;</span><br><span class="line"></span><br><span class="line">&#123;<span class="string">"id"</span>:4, <span class="string">"name"</span>:<span class="string">"Hanmeimei"</span>, <span class="string">"age"</span>:25&#125;</span><br><span class="line"></span><br><span class="line">&#123;<span class="string">"id"</span>:5, <span class="string">"name"</span>:<span class="string">"Lucy"</span>, <span class="string">"age"</span>:37&#125;</span><br><span class="line"></span><br><span class="line">&#123;<span class="string">"id"</span>:6, <span class="string">"name"</span>:<span class="string">"Tom"</span>, <span class="string">"age"</span>:27&#125;</span><br><span class="line"></span><br><span class="line">1,Ganymede,32</span><br><span class="line"></span><br><span class="line">2, Lilei, 19</span><br><span class="line"></span><br><span class="line">3, Lily, 25</span><br><span class="line"></span><br><span class="line">4, Hanmeimei, 25</span><br><span class="line"></span><br><span class="line">5, Lucy, 37</span><br><span class="line"></span><br><span class="line">6, wcc, 4</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br></pre></td><td class="code"><pre><span class="line">package DataCleaning</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">import org.apache.spark.sql.types._</span><br><span class="line">import org.apache.spark.sql.&#123;Row, SQLContext&#125;</span><br><span class="line">import org.apache.spark.&#123;SparkConf, SparkContext&#125;</span><br><span class="line"></span><br><span class="line">object DataFrameTest &#123;</span><br><span class="line">  <span class="keyword">case</span> class People(id: Int, name: String, age: Int)</span><br><span class="line">  def main(args: Array[String]): Unit = &#123;</span><br><span class="line">    val conf = new SparkConf().setAppName(<span class="string">"DataFrameTest"</span>).setMaster(<span class="string">"local"</span>)</span><br><span class="line"></span><br><span class="line">    val sc = new SparkContext(conf)</span><br><span class="line"></span><br><span class="line">    val sqlContxt = new SQLContext(sc)</span><br><span class="line"></span><br><span class="line">    val dfsql = sqlContxt.read.json(<span class="string">"people.json"</span>)</span><br><span class="line"></span><br><span class="line">    val dftxt = sc.textFile(<span class="string">"people.txt"</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    //映射表</span><br><span class="line">    dfsql.registerTempTable(<span class="string">"people"</span>)</span><br><span class="line"></span><br><span class="line">    dfsql.show()</span><br><span class="line">    dfsql.printSchema()</span><br><span class="line"></span><br><span class="line">    dfsql.select(dfsql.col(<span class="string">"id"</span>),dfsql.col(<span class="string">"name"</span>)).foreach( x =&amp;gt; &#123;</span><br><span class="line"></span><br><span class="line">      println(x.get(0),x.get(1))</span><br><span class="line">    &#125;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    dfsql.select(dfsql.col(<span class="string">"id"</span>),dfsql.col(<span class="string">"name"</span>)).foreachPartition( Iterator =&amp;gt;</span><br><span class="line">    Iterator.foreach(x =&amp;gt; &#123;</span><br><span class="line">      println(x.getAs(<span class="string">"id"</span>),x.getAs(<span class="string">"name"</span>))</span><br><span class="line">    &#125;))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    sqlContxt.sql(<span class="string">"select id,name from people"</span>).foreach( x =&amp;gt; &#123;</span><br><span class="line">      println(<span class="string">"SQL打印出来的````"</span>+x.get(0),x.get(1))</span><br><span class="line">    &#125;)</span><br><span class="line"></span><br><span class="line">    sqlContxt.sql(<span class="string">"select id,name from people"</span>).foreachPartition(Iterable =&amp;gt; &#123;</span><br><span class="line">      Iterable.foreach( x =&amp;gt; &#123;</span><br><span class="line">        println(<span class="string">"SQL打印出来的````"</span>+x.getAs(<span class="string">"id"</span>),x.getAs(<span class="string">"name"</span>))</span><br><span class="line">      &#125;)</span><br><span class="line">    &#125;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    val peopleRowRdd = dftxt.map(x =&amp;gt; x.split(<span class="string">","</span>)).map(data =&amp;gt;&#123;</span><br><span class="line">      val id = data(0).trim().toInt</span><br><span class="line">      val name = data(1).trim()</span><br><span class="line">      val age = data(2).trim().toInt</span><br><span class="line">      Row(id,name,age)</span><br><span class="line"></span><br><span class="line">    &#125;)</span><br><span class="line">    val structType = StructType(Array(</span><br><span class="line">      StructField(<span class="string">"id"</span>, IntegerType, <span class="literal">true</span>),</span><br><span class="line">      StructField(<span class="string">"name"</span>,StringType,<span class="literal">true</span> ),</span><br><span class="line">      StructField(<span class="string">"age"</span>, IntegerType, <span class="literal">true</span>)</span><br><span class="line">    ))</span><br><span class="line"></span><br><span class="line">    val df = sqlContxt.createDataFrame(peopleRowRdd, structType)</span><br><span class="line"></span><br><span class="line">    df.registerTempTable(<span class="string">"people1"</span>)</span><br><span class="line">    println(<span class="string">"-------------------"</span>)</span><br><span class="line">    df.show()</span><br><span class="line">    df.printSchema()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    val people = sc.textFile(<span class="string">"people.txt"</span>)</span><br><span class="line"></span><br><span class="line">    val peopleRDD = people.map &#123; x =&amp;gt; x.split(<span class="string">","</span>) &#125;.map ( data =&amp;gt;</span><br><span class="line">    &#123;</span><br><span class="line">      People(data(0).trim().toInt, data(1).trim(), data(2).trim().toInt)</span><br><span class="line">    &#125;)</span><br><span class="line"></span><br><span class="line">    //这里需要隐式转换一把</span><br><span class="line">    import sqlContxt.implicits._</span><br><span class="line">    val dfDF = peopleRDD.toDF()</span><br><span class="line">    dfDF.registerTempTable(<span class="string">"people"</span>)</span><br><span class="line"></span><br><span class="line">    println(<span class="string">"-------------case class反射来映射注册临时表-----------------------"</span>)</span><br><span class="line">    dfDF.show()</span><br><span class="line">    dfDF.printSchema()</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>


      
    </div>
    
    <div class="article-info article-info-index">
      
      
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/bigdata/">bigdata</a>
    </div>


      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/spark/" rel="tag">spark</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>











  
    <article id="post-9" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a  href="/2019/04/02/9/" class="article-date">
      <time datetime="2019-04-02T03:01:24.000Z" itemprop="datePublished">2019-04-02</time>
</a>

    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a  class="article-title" href="/2019/04/02/9/">Kafka HA Kafka一致性重要机制之ISR(kafka replica)</a>
    </h1>
  


      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <h3 id="一、kafka-replica"><a href="#一、kafka-replica" class="headerlink" title="一、kafka replica"></a>一、kafka replica</h3><p> 当某个topic的replication-factor为N且N大于1时，每个Partition都会有N个副本(Replica)。kafka的replica包含leader与follower。<br> Replica的个数小于等于Broker的个数，也就是说，对于每个Partition而言，每个Broker上最多只会有一个Replica，因此可以使用Broker id 指定Partition的Replica。<br> 所有Partition的Replica默认情况会均匀分布到所有Broker上。</p>
<h3 id="二、Data-Replication如何Propagate-扩散出去-消息？"><a href="#二、Data-Replication如何Propagate-扩散出去-消息？" class="headerlink" title="二、Data Replication如何Propagate(扩散出去)消息？"></a>二、Data Replication如何Propagate(扩散出去)消息？</h3><p>每个Partition有一个leader与多个follower，producer往某个Partition中写入数据是，只会往leader中写入数据，然后数据才会被复制进其他的Replica中。<br>数据是由leader push过去还是有flower pull过来？<br>kafka是由follower周期性或者尝试去pull(拉)过来(其实这个过程与consumer消费过程非常相似)，写是都往leader上写，但是读并不是任意flower上读都行，读也只在leader上读，flower只是数据的一个备份，保证leader被挂掉后顶上来，并不往外提供服务。</p>
<h3 id="三、Data-Replication何时Commit？"><a href="#三、Data-Replication何时Commit？" class="headerlink" title="三、Data Replication何时Commit？"></a>三、Data Replication何时Commit？</h3><p>同步复制： 只有所有的follower把数据拿过去后才commit，一致性好，可用性不高。<br>异步复制： 只要leader拿到数据立即commit，等follower慢慢去复制，可用性高，立即返回，一致性差一些。<br>Commit：是指leader告诉客户端，这条数据写成功了。kafka尽量保证commit后立即leader挂掉，其他flower都有该条数据</p>
<h3 id="kafka不是完全同步，也不是完全异步，是一种ISR机制"><a href="#kafka不是完全同步，也不是完全异步，是一种ISR机制" class="headerlink" title="kafka不是完全同步，也不是完全异步，是一种ISR机制"></a>kafka不是完全同步，也不是完全异步，是一种ISR机制</h3><p> leader会维护一个与其基本保持同步的Replica列表，该列表称为ISR(in-sync Replica)，每个Partition都会有一个ISR，而且是由leader动态维护<br> 如果一个flower比一个leader落后太多，或者超过一定时间未发起数据复制请求，则leader将其重ISR中移除<br> 当ISR中所有Replica都向Leader发送ACK时，leader才commit既然所有Replica都向Leader发送ACK时，leader才commit，那么flower怎么会leader落后太多？<br>producer往kafka中发送数据，不仅可以一次发送一条数据，还可以发送message的数组；批量发送，同步的时候批量发送，异步的时候本身就是就是批量；底层会有队列缓存起来，批量发送，对应broker而言，就会收到很多数据(假设1000)，这时候leader发现自己有1000条数据，flower只有500条数据，落后了500条数据，就把它从ISR中移除出去，这时候发现其他的flower与他的差距都很小，就等待；如果因为内存等原因，差距很大，就把它从ISR中移除出去。</p>
<h3 id="server配置"><a href="#server配置" class="headerlink" title="server配置"></a>server配置</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">rerplica.lag.time.max.ms=10000</span><br><span class="line"> <span class="comment"># 如果leader发现flower超过10秒没有向它发起fech请求，那么leader考虑这个flower是不是程序出了点问题</span></span><br><span class="line"> <span class="comment"># 或者资源紧张调度不过来，它太慢了，不希望它拖慢后面的进度，就把它从ISR中移除。</span></span><br><span class="line"></span><br><span class="line"> rerplica.lag.max.messages=4000 <span class="comment"># 相差4000条就移除</span></span><br><span class="line"> <span class="comment"># flower慢的时候，保证高可用性，同时满足这两个条件后又加入ISR中，</span></span><br><span class="line"> <span class="comment"># 在可用性与一致性做了动态平衡   亮点</span></span><br></pre></td></tr></table></figure>
<h3 id="topic配置"><a href="#topic配置" class="headerlink" title="topic配置"></a>topic配置</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">min.insync.replicas=1 <span class="comment"># 需要保证ISR中至少有多少个replica</span></span><br></pre></td></tr></table></figure>

<h3 id="Producer配置"><a href="#Producer配置" class="headerlink" title="Producer配置"></a>Producer配置</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">request.required.asks=0</span><br><span class="line"> <span class="comment"># 0:相当于异步的，不需要leader给予回复，producer立即返回，发送就是成功,</span></span><br><span class="line">     那么发送消息网络超时或broker crash(1.Partition的Leader还没有commit消息 2.Leader与Follower数据不同步)，</span><br><span class="line">     既有可能丢失也可能会重发</span><br><span class="line"> <span class="comment"># 1：当leader接收到消息之后发送ack，丢会重发，丢的概率很小</span></span><br><span class="line"> <span class="comment"># -1：当所有的follower都同步消息成功后发送ack.  丢失消息可能性比较低</span></span><br></pre></td></tr></table></figure>

<h3 id="Data-Replication如何处理Replica恢复"><a href="#Data-Replication如何处理Replica恢复" class="headerlink" title="Data Replication如何处理Replica恢复"></a>Data Replication如何处理Replica恢复</h3><p>leader挂掉了，从它的follower中选举一个作为leader，并把挂掉的leader从ISR中移除，继续处理数据。一段时间后该leader重新启动了，它知道它之前的数据到哪里了，尝试获取它挂掉后leader处理的数据，获取完成后它就加入了ISR。</p>
<h3 id="Data-Replication如何处理Replica全部宕机"><a href="#Data-Replication如何处理Replica全部宕机" class="headerlink" title="Data Replication如何处理Replica全部宕机"></a>Data Replication如何处理Replica全部宕机</h3><p> 等待ISR中任一Replica恢复,并选它为Leader 等待时间较长,降低可用性或ISR中的所有Replica都无法恢复或者数据丢失,则该Partition将永不可用<br> 选择第一个恢复的Replica为新的Leader,无论它是否在ISR中并未包含所有已被之前Leader Commit过的消息,因此会造成数据丢失可用性较高</p>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/bigdata/">bigdata</a>
    </div>


      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/spark/" rel="tag">spark</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>











  
    <article id="post-4" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a  href="/2019/03/02/4/" class="article-date">
      <time datetime="2019-03-02T15:01:24.000Z" itemprop="datePublished">2019-03-02</time>
</a>

    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a  class="article-title" href="/2019/03/02/4/">Spark scala 抽取mysql数据 导入Hive</a>
    </h1>
  


      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">driverClass=com.mysql.jdbc.Driver</span><br><span class="line">feeds.jdbcUrl=jdbc:mysql://172.16.XX.X:3306/feeds?useUnicode=<span class="literal">true</span>&amp;characterEncoding=utf8&amp;tinyInt1isBit=<span class="literal">false</span>&amp;autoReconnect=<span class="literal">true</span>&amp;useSSL=<span class="literal">false</span></span><br><span class="line">feeds.user=root</span><br><span class="line">feeds.password=Xingrui@jiatuimysql</span><br><span class="line"></span><br><span class="line">initialPoolSize=3</span><br><span class="line">minPoolSize=3</span><br><span class="line">acquireIncrement=3</span><br><span class="line">maxPoolSize=15</span><br><span class="line">maxIdleTime=10</span><br><span class="line">acquireRetryAttempts=30</span><br><span class="line">acquireRetryDelay=1000</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br></pre></td><td class="code"><pre><span class="line">&lt;project xmlns=<span class="string">"http://maven.apache.org/POM/4.0.0"</span> xmlns:xsi=<span class="string">"http://www.w3.org/2001/XMLSchema-instance"</span> xsi:schemaLocation=<span class="string">"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd"</span>&gt;</span><br><span class="line">  &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt;</span><br><span class="line">  &lt;groupId&gt;bigdata_cardevent_etl&lt;/groupId&gt;</span><br><span class="line">  &lt;artifactId&gt;bigdata_cardevent_etl&lt;/artifactId&gt;</span><br><span class="line">  &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;</span><br><span class="line">  &lt;name&gt;<span class="variable">$&#123;project.artifactId&#125;</span>&lt;/name&gt;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  &lt;properties&gt;</span><br><span class="line">		&lt;encoding&gt;UTF-8&lt;/encoding&gt;</span><br><span class="line">		&lt;spark.version&gt;1.6.3&lt;/spark.version&gt;</span><br><span class="line">		&lt;mysql.version&gt;5.1.47&lt;/mysql.version&gt;</span><br><span class="line">		&lt;c3p0.version&gt;0.9.5-pre4&lt;/c3p0.version&gt;</span><br><span class="line">    	&lt;fastjson.version&gt;1.2.47&lt;/fastjson.version&gt;</span><br><span class="line">    	</span><br><span class="line">	&lt;/properties&gt;</span><br><span class="line"></span><br><span class="line">	&lt;dependencies&gt;    </span><br><span class="line">		&lt;dependency&gt;</span><br><span class="line">			&lt;groupId&gt;org.apache.spark&lt;/groupId&gt;</span><br><span class="line">			&lt;artifactId&gt;spark-core_2.10&lt;/artifactId&gt;</span><br><span class="line">			&lt;version&gt;<span class="variable">$&#123;spark.version&#125;</span>&lt;/version&gt;</span><br><span class="line">			&lt;scope&gt;provided&lt;/scope&gt;</span><br><span class="line">		&lt;/dependency&gt;</span><br><span class="line">		&lt;dependency&gt;</span><br><span class="line">			&lt;groupId&gt;org.apache.spark&lt;/groupId&gt;</span><br><span class="line">			&lt;artifactId&gt;spark-hive_2.10&lt;/artifactId&gt;</span><br><span class="line">			&lt;version&gt;<span class="variable">$&#123;spark.version&#125;</span>&lt;/version&gt;</span><br><span class="line">			&lt;scope&gt;provided&lt;/scope&gt;</span><br><span class="line">		&lt;/dependency&gt;</span><br><span class="line">		&lt;dependency&gt;</span><br><span class="line">		    &lt;groupId&gt;mysql&lt;/groupId&gt;</span><br><span class="line">		    &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt;</span><br><span class="line">		    &lt;version&gt;<span class="variable">$&#123;mysql.version&#125;</span>&lt;/version&gt;</span><br><span class="line">		&lt;/dependency&gt;</span><br><span class="line">		&lt;dependency&gt;</span><br><span class="line">      		&lt;groupId&gt;com.alibaba&lt;/groupId&gt;</span><br><span class="line">      		&lt;artifactId&gt;fastjson&lt;/artifactId&gt;</span><br><span class="line">      		&lt;version&gt;<span class="variable">$&#123;fastjson.version&#125;</span>&lt;/version&gt;</span><br><span class="line">    	&lt;/dependency&gt;</span><br><span class="line">	&lt;dependency&gt;</span><br><span class="line">		    &lt;groupId&gt;com.mchange&lt;/groupId&gt;</span><br><span class="line">		    &lt;artifactId&gt;c3p0&lt;/artifactId&gt;</span><br><span class="line">		    &lt;version&gt;<span class="variable">$&#123;c3p0.version&#125;</span>&lt;/version&gt;</span><br><span class="line">		&lt;/dependency&gt;</span><br><span class="line">	&lt;/dependencies&gt;</span><br><span class="line"></span><br><span class="line">	&lt;build&gt;</span><br><span class="line">		&lt;sourceDirectory&gt;src/main/scala&lt;/sourceDirectory&gt;</span><br><span class="line">		&lt;testSourceDirectory&gt;src/<span class="built_in">test</span>/scala&lt;/testSourceDirectory&gt;</span><br><span class="line">		&lt;plugins&gt;</span><br><span class="line">			&lt;!-- compiler插件, 设定JDK版本 --&gt;</span><br><span class="line">			&lt;plugin&gt;</span><br><span class="line">				&lt;groupId&gt;org.scala-tools&lt;/groupId&gt;</span><br><span class="line">				&lt;artifactId&gt;maven-scala-plugin&lt;/artifactId&gt;</span><br><span class="line">				&lt;version&gt;2.15.2&lt;/version&gt;</span><br><span class="line">				&lt;executions&gt;</span><br><span class="line">					&lt;execution&gt;</span><br><span class="line">						&lt;goals&gt;</span><br><span class="line">							&lt;goal&gt;compile&lt;/goal&gt;</span><br><span class="line">						&lt;/goals&gt;</span><br><span class="line">					&lt;/execution&gt;</span><br><span class="line">				&lt;/executions&gt;</span><br><span class="line">			&lt;/plugin&gt;</span><br><span class="line">			&lt;plugin&gt;</span><br><span class="line">				&lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;</span><br><span class="line">				&lt;artifactId&gt;maven-shade-plugin&lt;/artifactId&gt;</span><br><span class="line">				&lt;version&gt;1.6&lt;/version&gt;</span><br><span class="line">				&lt;configuration&gt;</span><br><span class="line">					&lt;createDependencyReducedPom&gt;<span class="literal">true</span>&lt;/createDependencyReducedPom&gt;</span><br><span class="line">					&lt;<span class="built_in">source</span>&gt;1.8&lt;/<span class="built_in">source</span>&gt;</span><br><span class="line">					&lt;target&gt;1.8&lt;/target&gt;</span><br><span class="line">					&lt;filters&gt;</span><br><span class="line">						&lt;filter&gt;</span><br><span class="line">							&lt;artifact&gt;*:*&lt;/artifact&gt;</span><br><span class="line">							&lt;excludes&gt;</span><br><span class="line">								&lt;exclude&gt;META-INF/*.SF&lt;/exclude&gt;</span><br><span class="line">								&lt;exclude&gt;META-INF/*.DSA&lt;/exclude&gt;</span><br><span class="line">								&lt;exclude&gt;META-INF/*.RSA&lt;/exclude&gt;</span><br><span class="line">							&lt;/excludes&gt;</span><br><span class="line">						&lt;/filter&gt;</span><br><span class="line">					&lt;/filters&gt;</span><br><span class="line">				&lt;/configuration&gt;</span><br><span class="line">				&lt;executions&gt;</span><br><span class="line">					&lt;execution&gt;</span><br><span class="line">						&lt;phase&gt;package&lt;/phase&gt;</span><br><span class="line">						&lt;goals&gt;</span><br><span class="line">							&lt;goal&gt;shade&lt;/goal&gt;</span><br><span class="line">						&lt;/goals&gt;</span><br><span class="line">						&lt;configuration&gt;</span><br><span class="line">							&lt;transformers&gt;</span><br><span class="line">								&lt;transformer</span><br><span class="line">									implementation=<span class="string">"org.apache.maven.plugins.shade.resource.AppendingTransformer"</span>&gt;</span><br><span class="line">									&lt;resource&gt;reference.conf&lt;/resource&gt;</span><br><span class="line">								&lt;/transformer&gt;</span><br><span class="line">								&lt;transformer</span><br><span class="line">									implementation=<span class="string">"org.apache.maven.plugins.shade.resource.ServicesResourceTransformer"</span> /&gt;</span><br><span class="line">								&lt;transformer</span><br><span class="line">									implementation=<span class="string">"org.apache.maven.plugins.shade.resource.ManifestResourceTransformer"</span>&gt;</span><br><span class="line">									&lt;mainClass&gt;com.jiatui.bigdata.format.sdklog.main.FormatSdkLogApp&lt;/mainClass&gt;</span><br><span class="line">								&lt;/transformer&gt;</span><br><span class="line">							&lt;/transformers&gt;</span><br><span class="line">						&lt;/configuration&gt;</span><br><span class="line">					&lt;/execution&gt;</span><br><span class="line">				&lt;/executions&gt;</span><br><span class="line">			&lt;/plugin&gt;</span><br><span class="line">		&lt;/plugins&gt;</span><br><span class="line">	&lt;/build&gt;</span><br><span class="line">&lt;/project&gt;</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line">package com.jiatui.bigdata.util</span><br><span class="line"></span><br><span class="line">import com.mchange.v2.c3p0.ComboPooledDataSource</span><br><span class="line">import java.util.Properties</span><br><span class="line">import java.io.File</span><br><span class="line">import java.io.FileInputStream</span><br><span class="line">import java.sql.Connection</span><br><span class="line">import scala.collection.mutable.ArrayBuffer</span><br><span class="line">import java.sql.ResultSet</span><br><span class="line">/**</span><br><span class="line"> * c3p0连接</span><br><span class="line"> */</span><br><span class="line">class DBUtilC3p0() extends Serializable&#123;</span><br><span class="line">      private val cpds: ComboPooledDataSource =new ComboPooledDataSource(<span class="literal">true</span>)</span><br><span class="line">      </span><br><span class="line">      private val prop=new Properties</span><br><span class="line">      </span><br><span class="line">&#123;</span><br><span class="line">    try &#123;</span><br><span class="line">      val file: File = new File(<span class="string">"c3p0.properties"</span>)</span><br><span class="line">      val <span class="keyword">in</span> = new FileInputStream(file)</span><br><span class="line">      prop.load(<span class="keyword">in</span>)</span><br><span class="line">      println(<span class="string">"prop:"</span> + prop)</span><br><span class="line">      cpds.setJdbcUrl(prop.getProperty(<span class="string">"feeds.jdbcUrl"</span>))</span><br><span class="line">      cpds.setDriverClass(prop.getProperty(<span class="string">"driverClass"</span>))</span><br><span class="line">      cpds.setUser(prop.getProperty(<span class="string">"feeds.user"</span>))</span><br><span class="line">      cpds.setPassword(prop.getProperty(<span class="string">"feeds.password"</span>))</span><br><span class="line">      cpds.setMaxPoolSize(Integer.valueOf(prop.getProperty(<span class="string">"maxPoolSize"</span>)))</span><br><span class="line">      cpds.setMinPoolSize(Integer.valueOf(prop.getProperty(<span class="string">"minPoolSize"</span>)))</span><br><span class="line">      cpds.setAcquireIncrement(Integer.valueOf(prop.getProperty(<span class="string">"acquireIncrement"</span>)))</span><br><span class="line">      cpds.setInitialPoolSize(Integer.valueOf(prop.getProperty(<span class="string">"initialPoolSize"</span>)))</span><br><span class="line">      cpds.setMaxIdleTime(Integer.valueOf(prop.getProperty(<span class="string">"maxIdleTime"</span>)))</span><br><span class="line">    &#125; catch &#123;</span><br><span class="line">      <span class="keyword">case</span> ex: Exception =&gt; ex.printStackTrace()</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">      </span><br><span class="line">   </span><br><span class="line">      </span><br><span class="line">def getConnection: Connection = &#123;</span><br><span class="line">    try &#123;</span><br><span class="line">      cpds.getConnection()</span><br><span class="line">    &#125; catch &#123;</span><br><span class="line">      <span class="keyword">case</span> ex: Exception =&gt;</span><br><span class="line">        ex.printStackTrace()</span><br><span class="line">        null</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line">object DBUtilC3p0 &#123;</span><br><span class="line">  var dbUtilC3p0: DBUtilC3p0 = _</span><br><span class="line">  def getDBUtilC3p0(): DBUtilC3p0 = &#123;</span><br><span class="line">    synchronized &#123;</span><br><span class="line">      <span class="keyword">if</span> (dbUtilC3p0 == null) &#123;</span><br><span class="line">        dbUtilC3p0 = new DBUtilC3p0()</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    dbUtilC3p0</span><br><span class="line">  &#125;   </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br></pre></td><td class="code"><pre><span class="line">package com.jiatui.bigdata.util</span><br><span class="line"></span><br><span class="line">import java.sql.ResultSet</span><br><span class="line">import java.sql.Connection</span><br><span class="line">import java.sql.PreparedStatement</span><br><span class="line">import java.util.concurrent.BlockingQueue</span><br><span class="line">import java.util.concurrent.LinkedBlockingQueue</span><br><span class="line">import java.sql.DriverManager</span><br><span class="line">import jodd.util.PropertiesUtil</span><br><span class="line">import scala.collection.mutable.ArrayBuffer</span><br><span class="line"></span><br><span class="line">/*</span><br><span class="line"> * &lt;p&gt;Title: CardEventEtl&lt;/p&gt;</span><br><span class="line"> *</span><br><span class="line"> * &lt;p&gt;Description:获取feeds所有数据表名 &lt;/p&gt;</span><br><span class="line"> *</span><br><span class="line"> * @author zhangshuai</span><br><span class="line"> *</span><br><span class="line"> * @date 2019年3月1日</span><br><span class="line"> */</span><br><span class="line"></span><br><span class="line">object DBUtil &#123;</span><br><span class="line"></span><br><span class="line">def getFeedsTableNames() = &#123;</span><br><span class="line">    var data = new ArrayBuffer[String]()</span><br><span class="line">    val conn = DBUtilC3p0.getDBUtilC3p0().getConnection</span><br><span class="line">    try &#123;</span><br><span class="line">      val <span class="built_in">stat</span> = conn.createStatement()</span><br><span class="line">      val rs: ResultSet = stat.executeQuery(<span class="string">"show tables like '%_card_event'"</span>)</span><br><span class="line"></span><br><span class="line">      <span class="keyword">while</span> (rs.next()) &#123;</span><br><span class="line">        val tableName = rs.getString(1)</span><br><span class="line"></span><br><span class="line">          data += tableName</span><br><span class="line">       </span><br><span class="line">      &#125;</span><br><span class="line">      rs.close()</span><br><span class="line">      stat.close()</span><br><span class="line">      data</span><br><span class="line">    &#125; catch &#123;</span><br><span class="line">      <span class="keyword">case</span> t: Exception =&gt;</span><br><span class="line">        t.printStackTrace()</span><br><span class="line">        println(<span class="string">"获取feeds表表名时候出错."</span>)</span><br><span class="line">    &#125; finally &#123;</span><br><span class="line">      try &#123;</span><br><span class="line">        <span class="keyword">if</span> (conn != null) &#123;</span><br><span class="line">          conn.close()</span><br><span class="line">        &#125;</span><br><span class="line">      &#125; catch &#123;</span><br><span class="line">        <span class="keyword">case</span> t: Exception =&gt;</span><br><span class="line">          t.printStackTrace()</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    data</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">//  private var connection: Connection = _</span><br><span class="line">//</span><br><span class="line">//  private var preparedStatement: PreparedStatement = _</span><br><span class="line">//</span><br><span class="line">//  private var resultSet: ResultSet = _</span><br><span class="line">//</span><br><span class="line">//  def getCardEventTableNames = &#123;</span><br><span class="line">//    var data = new ArrayBuffer[String]()</span><br><span class="line">//    val conn = DBUtil.getConnection</span><br><span class="line">//    try &#123;</span><br><span class="line">//      val <span class="built_in">stat</span> = conn.createStatement()</span><br><span class="line">//      val rs: ResultSet = stat.executeQuery(<span class="string">"show tables like '%_card_event'"</span>)</span><br><span class="line">//</span><br><span class="line">//      <span class="keyword">while</span> (rs.next()) &#123;</span><br><span class="line">//        val tableName = rs.getString(1)</span><br><span class="line">//</span><br><span class="line">//        data += tableName</span><br><span class="line">//</span><br><span class="line">//      &#125;</span><br><span class="line">//      rs.close()</span><br><span class="line">//      stat.close()</span><br><span class="line">//      data</span><br><span class="line">//    &#125; catch &#123;</span><br><span class="line">//      <span class="keyword">case</span> t: Exception =&gt;</span><br><span class="line">//        t.printStackTrace()</span><br><span class="line">//        println(<span class="string">"获取统计表表名时候出错."</span>)</span><br><span class="line">//    &#125; finally &#123;</span><br><span class="line">//</span><br><span class="line">//      try &#123;</span><br><span class="line">//        <span class="keyword">if</span> (conn != null) &#123;</span><br><span class="line">//          conn.close()</span><br><span class="line">//</span><br><span class="line">//        &#125;</span><br><span class="line">//</span><br><span class="line">//      &#125; catch &#123;</span><br><span class="line">//        <span class="keyword">case</span> t: Exception =&gt;</span><br><span class="line">//          t.printStackTrace()</span><br><span class="line">//      &#125;</span><br><span class="line">//</span><br><span class="line">//    &#125;</span><br><span class="line">//    data</span><br><span class="line">//</span><br><span class="line">//  &#125;</span><br><span class="line">//</span><br><span class="line">//  </span><br><span class="line">// def getFeedsConnection: Connection =&#123;</span><br><span class="line">//    DBUtil.getConnection</span><br><span class="line">// &#125;</span><br><span class="line">//  </span><br><span class="line">//  </span><br><span class="line">//  </span><br><span class="line">//  // 数据库驱动类</span><br><span class="line">//</span><br><span class="line">//  private val driverClass: String = ConfigurationManager.getProperty(<span class="string">"driverClass"</span>)</span><br><span class="line">//  // 数据库连接地址</span><br><span class="line">//  private val url: String = ConfigurationManager.getProperty(<span class="string">"feeds.jdbcUrl"</span>)</span><br><span class="line">//</span><br><span class="line">//  // 数据库连接用户名</span><br><span class="line">//  private val username: String = ConfigurationManager.getProperty(<span class="string">"feeds.user"</span>)</span><br><span class="line">//  // 数据库连接密码</span><br><span class="line">//  private val password: String = ConfigurationManager.getProperty(<span class="string">"feeds.password"</span>)</span><br><span class="line">//</span><br><span class="line">//  // 加载数据库驱动</span><br><span class="line">//  //  Class.forName(driverClass)</span><br><span class="line">//  Class.forName(<span class="string">"com.mysql.jdbc.Driver"</span>)</span><br><span class="line">//</span><br><span class="line">//  // 连接池大小</span><br><span class="line">//  val poolSize: Int = ConfigurationManager.getProperty(<span class="string">"poolSize"</span>).toInt</span><br><span class="line">//</span><br><span class="line">//  // 连接池 - 同步队列</span><br><span class="line">//  private val pool: BlockingQueue[Connection] = new LinkedBlockingQueue[Connection]()</span><br><span class="line">//</span><br><span class="line">//  /**</span><br><span class="line">//   * 初始化连接池</span><br><span class="line">//   */</span><br><span class="line">//  <span class="keyword">for</span> (i &lt;- 1 to poolSize) &#123;</span><br><span class="line">//    DBUtil.pool.put(DriverManager.getConnection(url, username, password))</span><br><span class="line">//  &#125;</span><br><span class="line">//</span><br><span class="line">//  /**</span><br><span class="line">//   * 从连接池中获取一个Connection</span><br><span class="line">//   * @<span class="built_in">return</span></span><br><span class="line">//   */</span><br><span class="line">//  private def getConnection: Connection = &#123;</span><br><span class="line">//    pool.take()</span><br><span class="line">//  &#125;</span><br><span class="line">//</span><br><span class="line">//  /**</span><br><span class="line">//   * 向连接池归还一个Connection</span><br><span class="line">//   * @param conn</span><br><span class="line">//   */</span><br><span class="line">//  private def returnConnection(conn: Connection): Unit = &#123;</span><br><span class="line">//    DBUtil.pool.put(conn)</span><br><span class="line">//  &#125;</span><br><span class="line">//</span><br><span class="line">//  /**</span><br><span class="line">//   * 启动守护线程释放资源</span><br><span class="line">//   */</span><br><span class="line">//  def releaseResource() = &#123;</span><br><span class="line">//    val thread = new Thread(new CloseRunnable)</span><br><span class="line">//    thread.setDaemon(<span class="literal">true</span>)</span><br><span class="line">//    thread.start()</span><br><span class="line">//  &#125;</span><br><span class="line">//</span><br><span class="line">//  /**</span><br><span class="line">//   * 关闭连接池连接资源类</span><br><span class="line">//   */</span><br><span class="line">//  class CloseRunnable extends Runnable &#123;</span><br><span class="line">//    override def run(): Unit = &#123;</span><br><span class="line">//      <span class="keyword">while</span> (DBUtil.pool.size &gt; 0) &#123;</span><br><span class="line">//        try &#123;</span><br><span class="line">//          //          println(s<span class="string">"当前连接池大小: <span class="variable">$&#123;DBUtil.pool.size&#125;</span>"</span>)</span><br><span class="line">//          DBUtil.pool.take().close()</span><br><span class="line">//        &#125; catch &#123;</span><br><span class="line">//          <span class="keyword">case</span> e: Exception =&gt; e.printStackTrace()</span><br><span class="line">//        &#125;</span><br><span class="line">//      &#125;</span><br><span class="line">//    &#125;</span><br><span class="line">//  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br></pre></td><td class="code"><pre><span class="line">package com.jiatui.bigdata.util</span><br><span class="line"></span><br><span class="line">import java.sql.ResultSet</span><br><span class="line">import java.sql.Connection</span><br><span class="line">import java.sql.PreparedStatement</span><br><span class="line">import java.util.concurrent.BlockingQueue</span><br><span class="line">import java.util.concurrent.LinkedBlockingQueue</span><br><span class="line">import java.sql.DriverManager</span><br><span class="line">import jodd.util.PropertiesUtil</span><br><span class="line">import scala.collection.mutable.ArrayBuffer</span><br><span class="line"></span><br><span class="line">/*</span><br><span class="line"> * &lt;p&gt;Title: CardEventEtl&lt;/p&gt;</span><br><span class="line"> *</span><br><span class="line"> * &lt;p&gt;Description:获取feeds所有数据表名 &lt;/p&gt;</span><br><span class="line"> *</span><br><span class="line"> * @author zhangshuai</span><br><span class="line"> *</span><br><span class="line"> * @date 2019年3月1日</span><br><span class="line"> */</span><br><span class="line"></span><br><span class="line">object DBUtil &#123;</span><br><span class="line"></span><br><span class="line">def getFeedsTableNames() = &#123;</span><br><span class="line">    var data = new ArrayBuffer[String]()</span><br><span class="line">    val conn = DBUtilC3p0.getDBUtilC3p0().getConnection</span><br><span class="line">    try &#123;</span><br><span class="line">      val <span class="built_in">stat</span> = conn.createStatement()</span><br><span class="line">      val rs: ResultSet = stat.executeQuery(<span class="string">"show tables like '%_card_event'"</span>)</span><br><span class="line"></span><br><span class="line">      <span class="keyword">while</span> (rs.next()) &#123;</span><br><span class="line">        val tableName = rs.getString(1)</span><br><span class="line"></span><br><span class="line">          data += tableName</span><br><span class="line">       </span><br><span class="line">      &#125;</span><br><span class="line">      rs.close()</span><br><span class="line">      stat.close()</span><br><span class="line">      data</span><br><span class="line">    &#125; catch &#123;</span><br><span class="line">      <span class="keyword">case</span> t: Exception =&gt;</span><br><span class="line">        t.printStackTrace()</span><br><span class="line">        println(<span class="string">"获取feeds表表名时候出错."</span>)</span><br><span class="line">    &#125; finally &#123;</span><br><span class="line">      try &#123;</span><br><span class="line">        <span class="keyword">if</span> (conn != null) &#123;</span><br><span class="line">          conn.close()</span><br><span class="line">        &#125;</span><br><span class="line">      &#125; catch &#123;</span><br><span class="line">        <span class="keyword">case</span> t: Exception =&gt;</span><br><span class="line">          t.printStackTrace()</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    data</span><br><span class="line">  &#125;</span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">//  private var connection: Connection = _</span><br><span class="line">//</span><br><span class="line">//  private var preparedStatement: PreparedStatement = _</span><br><span class="line">//</span><br><span class="line">//  private var resultSet: ResultSet = _</span><br><span class="line">//</span><br><span class="line">//  def getCardEventTableNames = &#123;</span><br><span class="line">//    var data = new ArrayBuffer[String]()</span><br><span class="line">//    val conn = DBUtil.getConnection</span><br><span class="line">//    try &#123;</span><br><span class="line">//      val <span class="built_in">stat</span> = conn.createStatement()</span><br><span class="line">//      val rs: ResultSet = stat.executeQuery(<span class="string">"show tables like '%_card_event'"</span>)</span><br><span class="line">//</span><br><span class="line">//      <span class="keyword">while</span> (rs.next()) &#123;</span><br><span class="line">//        val tableName = rs.getString(1)</span><br><span class="line">//</span><br><span class="line">//        data += tableName</span><br><span class="line">//</span><br><span class="line">//      &#125;</span><br><span class="line">//      rs.close()</span><br><span class="line">//      stat.close()</span><br><span class="line">//      data</span><br><span class="line">//    &#125; catch &#123;</span><br><span class="line">//      <span class="keyword">case</span> t: Exception =&gt;</span><br><span class="line">//        t.printStackTrace()</span><br><span class="line">//        println(<span class="string">"获取统计表表名时候出错."</span>)</span><br><span class="line">//    &#125; finally &#123;</span><br><span class="line">//</span><br><span class="line">//      try &#123;</span><br><span class="line">//        <span class="keyword">if</span> (conn != null) &#123;</span><br><span class="line">//          conn.close()</span><br><span class="line">//</span><br><span class="line">//        &#125;</span><br><span class="line">//</span><br><span class="line">//      &#125; catch &#123;</span><br><span class="line">//        <span class="keyword">case</span> t: Exception =&gt;</span><br><span class="line">//          t.printStackTrace()</span><br><span class="line">//      &#125;</span><br><span class="line">//</span><br><span class="line">//    &#125;</span><br><span class="line">//    data</span><br><span class="line">//</span><br><span class="line">//  &#125;</span><br><span class="line">//</span><br><span class="line">//  </span><br><span class="line">// def getFeedsConnection: Connection =&#123;</span><br><span class="line">//    DBUtil.getConnection</span><br><span class="line">// &#125;</span><br><span class="line">//  </span><br><span class="line">//  </span><br><span class="line">//  </span><br><span class="line">//  // 数据库驱动类</span><br><span class="line">//</span><br><span class="line">//  private val driverClass: String = ConfigurationManager.getProperty(<span class="string">"driverClass"</span>)</span><br><span class="line">//  // 数据库连接地址</span><br><span class="line">//  private val url: String = ConfigurationManager.getProperty(<span class="string">"feeds.jdbcUrl"</span>)</span><br><span class="line">//</span><br><span class="line">//  // 数据库连接用户名</span><br><span class="line">//  private val username: String = ConfigurationManager.getProperty(<span class="string">"feeds.user"</span>)</span><br><span class="line">//  // 数据库连接密码</span><br><span class="line">//  private val password: String = ConfigurationManager.getProperty(<span class="string">"feeds.password"</span>)</span><br><span class="line">//</span><br><span class="line">//  // 加载数据库驱动</span><br><span class="line">//  //  Class.forName(driverClass)</span><br><span class="line">//  Class.forName(<span class="string">"com.mysql.jdbc.Driver"</span>)</span><br><span class="line">//</span><br><span class="line">//  // 连接池大小</span><br><span class="line">//  val poolSize: Int = ConfigurationManager.getProperty(<span class="string">"poolSize"</span>).toInt</span><br><span class="line">//</span><br><span class="line">//  // 连接池 - 同步队列</span><br><span class="line">//  private val pool: BlockingQueue[Connection] = new LinkedBlockingQueue[Connection]()</span><br><span class="line">//</span><br><span class="line">//  /**</span><br><span class="line">//   * 初始化连接池</span><br><span class="line">//   */</span><br><span class="line">//  <span class="keyword">for</span> (i &lt;- 1 to poolSize) &#123;</span><br><span class="line">//    DBUtil.pool.put(DriverManager.getConnection(url, username, password))</span><br><span class="line">//  &#125;</span><br><span class="line">//</span><br><span class="line">//  /**</span><br><span class="line">//   * 从连接池中获取一个Connection</span><br><span class="line">//   * @<span class="built_in">return</span></span><br><span class="line">//   */</span><br><span class="line">//  private def getConnection: Connection = &#123;</span><br><span class="line">//    pool.take()</span><br><span class="line">//  &#125;</span><br><span class="line">//</span><br><span class="line">//  /**</span><br><span class="line">//   * 向连接池归还一个Connection</span><br><span class="line">//   * @param conn</span><br><span class="line">//   */</span><br><span class="line">//  private def returnConnection(conn: Connection): Unit = &#123;</span><br><span class="line">//    DBUtil.pool.put(conn)</span><br><span class="line">//  &#125;</span><br><span class="line">//</span><br><span class="line">//  /**</span><br><span class="line">//   * 启动守护线程释放资源</span><br><span class="line">//   */</span><br><span class="line">//  def releaseResource() = &#123;</span><br><span class="line">//    val thread = new Thread(new CloseRunnable)</span><br><span class="line">//    thread.setDaemon(<span class="literal">true</span>)</span><br><span class="line">//    thread.start()</span><br><span class="line">//  &#125;</span><br><span class="line">//</span><br><span class="line">//  /**</span><br><span class="line">//   * 关闭连接池连接资源类</span><br><span class="line">//   */</span><br><span class="line">//  class CloseRunnable extends Runnable &#123;</span><br><span class="line">//    override def run(): Unit = &#123;</span><br><span class="line">//      <span class="keyword">while</span> (DBUtil.pool.size &gt; 0) &#123;</span><br><span class="line">//        try &#123;</span><br><span class="line">//          //          println(s<span class="string">"当前连接池大小: <span class="variable">$&#123;DBUtil.pool.size&#125;</span>"</span>)</span><br><span class="line">//          DBUtil.pool.take().close()</span><br><span class="line">//        &#125; catch &#123;</span><br><span class="line">//          <span class="keyword">case</span> e: Exception =&gt; e.printStackTrace()</span><br><span class="line">//        &#125;</span><br><span class="line">//      &#125;</span><br><span class="line">//    &#125;</span><br><span class="line">//  &#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/bigdata/">bigdata</a>
    </div>


      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/spark/" rel="tag">spark</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>











  
    <article id="post-16" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a  href="/2018/12/02/16/" class="article-date">
      <time datetime="2018-12-02T13:01:24.000Z" itemprop="datePublished">2018-12-02</time>
</a>

    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a  class="article-title" href="/2018/12/02/16/">Kafka生产者详解</a>
    </h1>
  


      </header>
      
    
    <div class="article-entry" itemprop="articleBody">
      
          
        <h3 id="一、生产者发送消息的过程"><a href="#一、生产者发送消息的过程" class="headerlink" title="一、生产者发送消息的过程"></a>一、生产者发送消息的过程</h3><p>首先介绍一下 Kafka 生产者发送消息的过程：</p>
<p>Kafka 会将发送消息包装为 ProducerRecord 对象， ProducerRecord 对象包含了目标主题和要发送的内容，同时还可以指定键和分区。在发送 ProducerRecord 对象前，生产者会先把键和值对象序列化成字节数组，这样它们才能够在网络上传输。</p>
<p>接下来，数据被传给分区器。如果之前已经在 ProducerRecord 对象里指定了分区，那么分区器就不会再做任何事情。如果没有指定分区 ，那么分区器会根据 ProducerRecord 对象的键来选择一个分区，紧接着，这条记录被添加到一个记录批次里，这个批次里的所有消息会被发送到相同的主题和分区上。有一个独立的线程负责把这些记录批次发送到相应的 broker 上。</p>
<p>服务器在收到这些消息时会返回一个响应。如果消息成功写入 Kafka，就返回一个 RecordMetaData 对象，它包含了主题和分区信息，以及记录在分区里的偏移量。如果写入失败，则会返回一个错误。生产者在收到错误之后会尝试重新发送消息，如果达到指定的重试次数后还没有成功，则直接抛出异常，不再重试。</p>
<p><img src="/images/15.png" alt="alt"></p>
<h3 id="二、创建生产者"><a href="#二、创建生产者" class="headerlink" title="二、创建生产者"></a>二、创建生产者</h3><p>2.1 项目依赖<br>本项目采用 Maven 构建，想要调用 Kafka 生产者 API，需要导入 kafka-clients 依赖，如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;org.apache.kafka&lt;/groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;kafka-clients&lt;/artifactId&gt;</span><br><span class="line">    &lt;version&gt;2.2.0&lt;/version&gt;</span><br><span class="line">&lt;/dependency&gt;</span><br></pre></td></tr></table></figure>

<p>2.2 创建生产者<br>创建 Kafka 生产者时，以下三个属性是必须指定的：</p>
<p>bootstrap.servers ：指定 broker 的地址清单，清单里不需要包含所有的 broker 地址，生产者会从给定的 broker 里查找 broker 的信息。不过建议至少要提供两个 broker 的信息作为容错；<br>key.serializer ：指定键的序列化器；<br>value.serializer ：指定值的序列化器。</p>
<p>创建的示例代码如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">public class SimpleProducer &#123;</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line"></span><br><span class="line">        String topicName = <span class="string">"Hello-Kafka"</span>;</span><br><span class="line"></span><br><span class="line">        Properties props = new Properties();</span><br><span class="line">        props.put(<span class="string">"bootstrap.servers"</span>, <span class="string">"hadoop001:9092"</span>);</span><br><span class="line">        props.put(<span class="string">"key.serializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringSerializer"</span>);</span><br><span class="line">        props.put(<span class="string">"value.serializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringSerializer"</span>);</span><br><span class="line">        /*创建生产者*/</span><br><span class="line">        Producer&lt;String, String&gt; producer = new KafkaProducer&lt;&gt;(props);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (int i = 0; i &lt; 10; i++) &#123;</span><br><span class="line">            ProducerRecord&lt;String, String&gt; record = new ProducerRecord&lt;&gt;(topicName, <span class="string">"hello"</span> + i, </span><br><span class="line">                                                                         <span class="string">"world"</span> + i);</span><br><span class="line">            /* 发送消息*/</span><br><span class="line">            producer.send(record);</span><br><span class="line">        &#125;</span><br><span class="line">        /*关闭生产者*/</span><br><span class="line">        producer.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>2.3 测试</p>
<ol>
<li>启动Kakfa<br>Kafka 的运行依赖于 zookeeper，需要预先启动，可以启动 Kafka 内置的 zookeeper，也可以启动自己安装的：</li>
</ol>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># zookeeper启动命令</span></span><br><span class="line">bin/zkServer.sh start</span><br><span class="line"></span><br><span class="line"><span class="comment"># 内置zookeeper启动命令</span></span><br><span class="line">bin/zookeeper-server-start.sh config/zookeeper.properties</span><br></pre></td></tr></table></figure>

<p>启动单节点 kafka 用于测试：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># bin/kafka-server-start.sh config/server.properties</span></span><br></pre></td></tr></table></figure>

<ol start="2">
<li>创建topic<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 创建用于测试主题</span></span><br><span class="line">bin/kafka-topics.sh --create \</span><br><span class="line">                    --bootstrap-server hadoop001:9092 \</span><br><span class="line">                     --replication-factor 1 --partitions 1 \</span><br><span class="line">                     --topic Hello-Kafka</span><br><span class="line"></span><br><span class="line"><span class="comment"># 查看所有主题</span></span><br><span class="line"> bin/kafka-topics.sh --list --bootstrap-server hadoop001:9092</span><br></pre></td></tr></table></figure></li>
<li>运行项目<br>此时可以看到消费者控制台，输出如下，这里 kafka-console-consumer 只会打印出值信息，不会打印出键信息。<br><img src="/images/16.png" alt="alt"></li>
</ol>
<p>2.4 可能出现的问题<br>在这里可能出现的一个问题是：生产者程序在启动后，一直处于等待状态。这通常出现在你使用默认配置启动 Kafka 的情况下，此时需要对 server.properties 文件中的 listeners 配置进行更改</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># hadoop001 为我启动kafka服务的主机名，你可以换成自己的主机名或者ip地址</span></span><br><span class="line">listeners=PLAINTEXT://hadoop001:9092</span><br></pre></td></tr></table></figure>

<h3 id="二、发送消息"><a href="#二、发送消息" class="headerlink" title="二、发送消息"></a>二、发送消息</h3><p>上面的示例程序调用了 send 方法发送消息后没有做任何操作，在这种情况下，我们没有办法知道消息发送的结果。想要知道消息发送的结果，可以使用同步发送或者异步发送来实现。</p>
<p>2.1 同步发送<br>在调用 send 方法后可以接着调用 get() 方法，send 方法的返回值是一个 Future<RecordMetadata>对象，RecordMetadata 里面包含了发送消息的主题、分区、偏移量等信息。改写后的代码如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (int i = 0; i &lt; 10; i++) &#123;</span><br><span class="line">    try &#123;</span><br><span class="line">        ProducerRecord&lt;String, String&gt; record = new ProducerRecord&lt;&gt;(topicName, <span class="string">"k"</span> + i, <span class="string">"world"</span> + i);</span><br><span class="line">        /*同步发送消息*/</span><br><span class="line">        RecordMetadata metadata = producer.send(record).get();</span><br><span class="line">        System.out.printf(<span class="string">"topic=%s, partition=%d, offset=%s \n"</span>,</span><br><span class="line">                metadata.topic(), metadata.partition(), metadata.offset());</span><br><span class="line">    &#125; catch (InterruptedException | ExecutionException e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>此时得到的输出如下：偏移量和调用次数有关，所有记录都分配到了 0 分区，这是因为在创建 Hello-Kafka 主题时候，使用 –partitions 指定其分区数为 1，即只有一个分区。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">topic=Hello-Kafka, partition=0, offset=40 </span><br><span class="line">topic=Hello-Kafka, partition=0, offset=41 </span><br><span class="line">topic=Hello-Kafka, partition=0, offset=42 </span><br><span class="line">topic=Hello-Kafka, partition=0, offset=43 </span><br><span class="line">topic=Hello-Kafka, partition=0, offset=44 </span><br><span class="line">topic=Hello-Kafka, partition=0, offset=45 </span><br><span class="line">topic=Hello-Kafka, partition=0, offset=46 </span><br><span class="line">topic=Hello-Kafka, partition=0, offset=47 </span><br><span class="line">topic=Hello-Kafka, partition=0, offset=48 </span><br><span class="line">topic=Hello-Kafka, partition=0, offset=49</span><br></pre></td></tr></table></figure>
<p>2.2 异步发送<br>通常我们并不关心发送成功的情况，更多关注的是失败的情况，因此 Kafka 提供了异步发送和回调函数。 代码如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (int i = 0; i &lt; 10; i++) &#123;</span><br><span class="line">    ProducerRecord&lt;String, String&gt; record = new ProducerRecord&lt;&gt;(topicName, <span class="string">"k"</span> + i, <span class="string">"world"</span> + i);</span><br><span class="line">    /*异步发送消息，并监听回调*/</span><br><span class="line">    producer.send(record, new <span class="function"><span class="title">Callback</span></span>() &#123;</span><br><span class="line">        @Override</span><br><span class="line">        public void onCompletion(RecordMetadata metadata, Exception exception) &#123;</span><br><span class="line">            <span class="keyword">if</span> (exception != null) &#123;</span><br><span class="line">                System.out.println(<span class="string">"进行异常处理"</span>);</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                System.out.printf(<span class="string">"topic=%s, partition=%d, offset=%s \n"</span>,</span><br><span class="line">                        metadata.topic(), metadata.partition(), metadata.offset());</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="三、自定义分区器"><a href="#三、自定义分区器" class="headerlink" title="三、自定义分区器"></a>三、自定义分区器</h3><p>Kafka 有着默认的分区机制：</p>
<p>如果键值为 null， 则使用轮询 (Round Robin) 算法将消息均衡地分布到各个分区上；<br>如果键值不为 null，那么 Kafka 会使用内置的散列算法对键进行散列，然后分布到各个分区上。<br>某些情况下，你可能有着自己的分区需求，这时候可以采用自定义分区器实现。这里给出一个自定义分区器的示例</p>
<p>3.1 自定义分区器</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">/**</span><br><span class="line"> * 自定义分区器</span><br><span class="line"> */</span><br><span class="line">public class CustomPartitioner implements Partitioner &#123;</span><br><span class="line"></span><br><span class="line">    private int passLine;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public void configure(Map&lt;String, ?&gt; configs) &#123;</span><br><span class="line">        /*从生产者配置中获取分数线*/</span><br><span class="line">        passLine = (Integer) configs.get(<span class="string">"pass.line"</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public int partition(String topic, Object key, byte[] keyBytes, Object value, </span><br><span class="line">                         byte[] valueBytes, Cluster cluster) &#123;</span><br><span class="line">        /*key 值为分数，当分数大于分数线时候，分配到 1 分区，否则分配到 0 分区*/</span><br><span class="line">        <span class="built_in">return</span> (Integer) key &gt;= passLine ? 1 : 0;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    @Override</span><br><span class="line">    public void <span class="function"><span class="title">close</span></span>() &#123;</span><br><span class="line">        System.out.println(<span class="string">"分区器关闭"</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>需要在创建生产者时指定分区器，和分区器所需要的配置参数：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">public class ProducerWithPartitioner &#123;</span><br><span class="line"></span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line"></span><br><span class="line">        String topicName = <span class="string">"Kafka-Partitioner-Test"</span>;</span><br><span class="line"></span><br><span class="line">        Properties props = new Properties();</span><br><span class="line">        props.put(<span class="string">"bootstrap.servers"</span>, <span class="string">"hadoop001:9092"</span>);</span><br><span class="line">        props.put(<span class="string">"key.serializer"</span>, <span class="string">"org.apache.kafka.common.serialization.IntegerSerializer"</span>);</span><br><span class="line">        props.put(<span class="string">"value.serializer"</span>, <span class="string">"org.apache.kafka.common.serialization.StringSerializer"</span>);</span><br><span class="line"></span><br><span class="line">        /*传递自定义分区器*/</span><br><span class="line">        props.put(<span class="string">"partitioner.class"</span>, <span class="string">"com.heibaiying.producers.partitioners.CustomPartitioner"</span>);</span><br><span class="line">        /*传递分区器所需的参数*/</span><br><span class="line">        props.put(<span class="string">"pass.line"</span>, 6);</span><br><span class="line"></span><br><span class="line">        Producer&lt;Integer, String&gt; producer = new KafkaProducer&lt;&gt;(props);</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> (int i = 0; i &lt;= 10; i++) &#123;</span><br><span class="line">            String score = <span class="string">"score:"</span> + i;</span><br><span class="line">            ProducerRecord&lt;Integer, String&gt; record = new ProducerRecord&lt;&gt;(topicName, i, score);</span><br><span class="line">            /*异步发送消息*/</span><br><span class="line">            producer.send(record, (metadata, exception) -&gt;</span><br><span class="line">                    System.out.printf(<span class="string">"%s, partition=%d, \n"</span>, score, metadata.partition()));</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        producer.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>3.2 测试<br>需要创建一个至少有两个分区的主题：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-topics.sh --create \</span><br><span class="line">                   --bootstrap-server hadoop001:9092 \</span><br><span class="line">                    --replication-factor 1 --partitions 2 \</span><br><span class="line">                    --topic Kafka-Partitioner-Test</span><br></pre></td></tr></table></figure>
<p>此时输入如下，可以看到分数大于等于 6 分的都被分到 1 分区，而小于 6 分的都被分到了 0 分区。</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">score:6, partition=1, </span><br><span class="line">score:7, partition=1, </span><br><span class="line">score:8, partition=1, </span><br><span class="line">score:9, partition=1, </span><br><span class="line">score:10, partition=1, </span><br><span class="line">score:0, partition=0, </span><br><span class="line">score:1, partition=0, </span><br><span class="line">score:2, partition=0, </span><br><span class="line">score:3, partition=0, </span><br><span class="line">score:4, partition=0, </span><br><span class="line">score:5, partition=0, </span><br><span class="line">分区器关闭</span><br></pre></td></tr></table></figure>

<h3 id="四、生产者其他属性"><a href="#四、生产者其他属性" class="headerlink" title="四、生产者其他属性"></a>四、生产者其他属性</h3><p>上面生产者的创建都仅指定了服务地址，键序列化器、值序列化器，实际上 Kafka 的生产者还有很多可配置属性，如下：</p>
<ol>
<li>acks<br>acks 参数指定了必须要有多少个分区副本收到消息，生产者才会认为消息写入是成功的：</li>
</ol>
<p>acks=0 ： 消息发送出去就认为已经成功了，不会等待任何来自服务器的响应；<br>acks=1 ： 只要集群的首领节点收到消息，生产者就会收到一个来自服务器成功响应；<br>acks=all ：只有当所有参与复制的节点全部收到消息时，生产者才会收到一个来自服务器的成功响应。<br>2. buffer.memory<br>设置生产者内存缓冲区的大小。</p>
<ol start="3">
<li><p>compression.type<br>默认情况下，发送的消息不会被压缩。如果想要进行压缩，可以配置此参数，可选值有 snappy，gzip，lz4。</p>
</li>
<li><p>retries<br>发生错误后，消息重发的次数。如果达到设定值，生产者就会放弃重试并返回错误。</p>
</li>
<li><p>batch.size<br>当有多个消息需要被发送到同一个分区时，生产者会把它们放在同一个批次里。该参数指定了一个批次可以使用的内存大小，按照字节数计算。</p>
</li>
<li><p>linger.ms<br>该参数制定了生产者在发送批次之前等待更多消息加入批次的时间。</p>
</li>
<li><p>clent.id<br>客户端 id,服务器用来识别消息的来源。</p>
</li>
<li><p>max.in.flight.requests.per.connection<br>指定了生产者在收到服务器响应之前可以发送多少个消息。它的值越高，就会占用越多的内存，不过也会提升吞吐量，把它设置为 1 可以保证消息是按照发送的顺序写入服务器，即使发生了重试。</p>
</li>
<li><p>timeout.ms, request.timeout.ms &amp; metadata.fetch.timeout.ms<br>timeout.ms 指定了 borker 等待同步副本返回消息的确认时间；<br>request.timeout.ms 指定了生产者在发送数据时等待服务器返回响应的时间；<br>metadata.fetch.timeout.ms 指定了生产者在获取元数据（比如分区首领是谁）时等待服务器返回响应的时间。</p>
</li>
<li><p>max.block.ms<br>指定了在调用 send() 方法或使用 partitionsFor() 方法获取元数据时生产者的阻塞时间。当生产者的发送缓冲区已满，或者没有可用的元数据时，这些方法会阻塞。在阻塞时间达到 max.block.ms 时，生产者会抛出超时异常。</p>
</li>
<li><p>max.request.size<br>该参数用于控制生产者发送的请求大小。它可以指发送的单个消息的最大值，也可以指单个请求里所有消息总的大小。例如，假设这个值为 1000K ，那么可以发送的单个最大消息为 1000K ，或者生产者可以在单个请求里发送一个批次，该批次包含了 1000 个消息，每个消息大小为 1K。</p>
</li>
<li><p>receive.buffer.bytes &amp; send.buffer.byte<br>这两个参数分别指定 TCP socket 接收和发送数据包缓冲区的大小，-1 代表使用操作系统的默认值。</p>
</li>
</ol>

      
    </div>
    
    <div class="article-info article-info-index">
      
      
    <div class="article-category tagcloud">
    <a class="article-category-link" href="/categories/bigdata/">bigdata</a>
    </div>


      
    <div class="article-tag tagcloud">
        <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/kafka/" rel="tag">kafka</a></li></ul>
    </div>

      
      <div class="clearfix"></div>
    </div>
    
  </div>
  
</article>











  
  
    <nav id="page-nav">
      <a class="extend prev" rel="prev" href="/page/2/">&amp;laquo; Prev</a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><span class="page-number current">3</span><a class="page-number" href="/page/4/">4</a><a class="extend next" rel="next" href="/page/4/">Next &amp;raquo;</a>
    </nav>
  

</div>
      <footer id="footer">
    <div class="outer">
        <div id="footer-info">
            <div class="footer-left">
                &copy; 2023 
            </div>
            <div class="footer-right">
                <a href="http://hexo.io/" target="_blank">Hexo &nbsp;&nbsp;</a><a href="https://github.com/zhangdeshuai409930360" target="_blank">Blog</a> by handsomezhangshuai
            </div>
        </div>
        
            <div class="visit">
            © 2015-2020 zhangdeshuai 粤ICP备15075505号
            <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
            <span id="busuanzi_container_site_pv">本站总访问量<span id="busuanzi_value_site_pv"></span>次</span>
           </div>
        
    </div>
</footer>

    </div>
    
<script src="https://7.url.cn/edu/jslib/comb/require-2.1.6,jquery-1.9.1.min.js"></script>


<script src="/js/main.js"></script>


    <script>
        $(document).ready(function() {
            var backgroundnum = 1;
            var backgroundimg = "url(/background/bg-x.jpg)".replace(/x/gi, Math.ceil(Math.random() * backgroundnum));
            $("#mobile-nav").css({"background-image": backgroundimg,"background-size": "cover","background-position": "center"});
            $(".left-col").css({"background-image": backgroundimg,"background-size": "cover","background-position": "center"});
        })
    </script>


<!-- Google Analytics -->
<script type="text/javascript">
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'xxxxx', 'auto');
ga('send', 'pageview');

</script>
<!-- End Google Analytics -->



	<script>
	var _hmt = _hmt || [];
	(function() {
	  var hm = document.createElement("script");
	  hm.src = "//hm.baidu.com/hm.js?xxxxxx";
	  var s = document.getElementsByTagName("script")[0]; 
	  s.parentNode.insertBefore(hm, s);
	})();
	</script>



<div class="scroll" id="scroll">
    <a href="#"><i class="fa fa-arrow-up"></i></a>
    <a href="#comments"><i class="fa fa-comments-o"></i></a>
    <a href="#footer"><i class="fa fa-arrow-down"></i></a>
</div>
<script>
    $(document).ready(function() {
        if ($("#comments").length < 1) {
            $("#scroll > a:nth-child(2)").hide();
        };
    })
</script>

<script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js">
</script>

  <script language="javascript">
    $(function() {
        $("a[title]").each(function() {
            var a = $(this);
            var title = a.attr('title');
            if (title == undefined || title == "") return;
            a.data('title', title).removeAttr('title').hover(
            function() {
                var offset = a.offset();
                $("<div id=\"anchortitlecontainer\"></div>").appendTo($("body")).html(title).css({
                    top: offset.top - a.outerHeight() - 15,
                    left: offset.left + a.outerWidth()/2 + 1
                }).fadeIn(function() {
                    var pop = $(this);
                    setTimeout(function() {
                        pop.remove();
                    }, pop.text().length * 800);
                });
            }, function() {
                $("#anchortitlecontainer").remove();
            });
        });
    });
</script>


  </div>
</body>
</html>
